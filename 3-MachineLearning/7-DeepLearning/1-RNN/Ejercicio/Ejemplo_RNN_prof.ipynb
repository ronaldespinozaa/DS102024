{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN con California Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizaciones\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelo de aprendizaje\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Redes neuronales\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "feature_names = housing.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "df['Price'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tamaño de el dataset {df.shape}\")\n",
    "print(\"\\nInformacion de las columnas:\")\n",
    "print(df.info())\n",
    "print(\"\\nEstadísticas descriptivas\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la distribución de precios\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['Price'], kde=True);\n",
    "plt.title('Distribución de los precios de viviendas')\n",
    "plt.xlabel('Precio Medio de vivienda')\n",
    "plt.ylabel('Frecuencia');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "plt.figure(figsize=(12,8))\n",
    "correlacion_matrix = df.corr()\n",
    "sns.heatmap(correlacion_matrix, annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Matriz de Correlación\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaciones de relaciones entre feature y Price\n",
    "\n",
    "for feature in feature_names:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.scatterplot(x=df[feature], y=df['Price'], alpha=0.1)\n",
    "    plt.title(f\"Relación entre {feature} y Precio Medio de vivienda\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Precio')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en Train y Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=73)\n",
    "\n",
    "# Escalado de datos\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, learning_rate=0.001):\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    optimizador = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizador,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape= X_train_scaled.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback de entrenamiento\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=30,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    "    monitor='val_loss'\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.2,\n",
    "    patience=10,\n",
    "    min_lr=0.00001,\n",
    "    monitor='val_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el Modelo\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs = 300,\n",
    "    batch_size = 32,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled,y_test, verbose=0)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Test Root Mean Squared Error (RMSE): {rmse*100_000:.4f}\")\n",
    "print(f\"Test Mean Absolute Percentage Error (MAPE): {mape:.4f}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Test R-squared: {R2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'],label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'],label='Validación')\n",
    "plt.title('Pérdida (loss) durante el entrenamiento')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'],label='Entrenamiento')\n",
    "plt.plot(history.history['val_mae'],label='Validación')\n",
    "plt.title('MAE durante el entrenamiento')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend();\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_test,y_pred,alpha=0.3)\n",
    "plt.plot([y_test.min(),y_test.max()],[y_pred.min(),y_pred.max()], color='r')\n",
    "plt.xlabel('Precios reales ($100.000)')\n",
    "plt.xlabel('Predicciones ($100.000)')\n",
    "plt.title('Predicciones vs Valores Reales')\n",
    "plt.grid(True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = y_test - y_pred.flatten()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(y_pred, residuos, alpha=0.3)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Residuos')\n",
    "plt.title('Gráfico de Residuos')\n",
    "plt.grid(True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(residuos,kde=True)\n",
    "plt.title('Distribución de Residuos')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=73)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Importancia Relativa')\n",
    "plt.title('Importancia de las características')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de implementación con Keras Tuner\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "def build_model_tuner(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Primera capa densa con número de unidades variable\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "        activation='relu',\n",
    "        input_shape=(X_train.shape[1],)\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Capas ocultas adicionales (número variable)\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'units_{i+2}', min_value=16, max_value=128, step=16),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(hp.Float(f'dropout_{i+2}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Capa de salida\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Configurar la búsqueda\n",
    "tuner = RandomSearch(\n",
    "    build_model_tuner,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='housing_tuning',\n",
    "    project_name='california_housing'\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda\n",
    "tuner.search(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Mejores hiperparámetros: {best_hyperparameters.values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
