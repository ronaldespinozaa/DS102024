{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72efb76d",
   "metadata": {},
   "source": [
    "# **Aprendizaje en Conjunto y Random Forest**\n",
    "\n",
    "**Resumen:** En este capítulo exploraremos distintas técnicas de ensamblaje, incluyendo clasificadores por votación (hard y soft voting), bagging, pasting, bosques aleatorios, boosting (AdaBoost y Gradient Boosting) y stacking. Se muestran ejemplos prácticos y se explican los conceptos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afde95",
   "metadata": {},
   "source": [
    "# Clasificadores por Votación (Voting Classifiers)\n",
    "\n",
    "En esta sección se muestra primero cómo simular el comportamiento de la ley de los grandes números con lanzamientos de moneda, y luego se construye un clasificador por votación que combina distintos modelos.\n",
    "\n",
    "**Resumen:** Se ejemplifica la convergencia de la proporción de “caras” en lanzamientos de moneda y se muestra cómo combinar un clasificador de Regresión Logística, un Bosque Aleatorio y un SVM en un VotingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cf638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – esta celda genera y guarda la Figura 7–3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "heads_proba = 0.51\n",
    "np.random.seed(42)\n",
    "coin_tosses = (np.random.rand(10000, 10) < heads_proba).astype(np.int32)\n",
    "cumulative_heads = coin_tosses.cumsum(axis=0)\n",
    "cumulative_heads_ratio = cumulative_heads / np.arange(1, 10001).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(cumulative_heads_ratio)\n",
    "plt.plot([0, 10000], [0.51, 0.51], \"k--\", linewidth=2, label=\"51%\")\n",
    "plt.plot([0, 10000], [0.5, 0.5], \"k-\", label=\"50%\")\n",
    "plt.xlabel(\"Número de lanzamientos de moneda\")\n",
    "plt.ylabel(\"Proporción de caras\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.axis([0, 10000, 0.42, 0.58])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b04d24",
   "metadata": {},
   "source": [
    "A continuación, se construye un VotingClassifier combinando tres estimadores: Regresión Logística, Bosque Aleatorio y SVM. Primero se entrena cada uno por separado y se evalúa su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Generamos un dataset tipo \"moons\" (dos lunas) con ruido\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Definimos el VotingClassifier con tres estimadores\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svc', SVC(random_state=42))\n",
    "    ]\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07471b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el desempeño de cada clasificador individualmente\n",
    "for name, clf in voting_clf.named_estimators_.items():\n",
    "    print(name, \"=\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658793e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de predicción con el VotingClassifier sobre una instancia\n",
    "print(\"Predicción VotingClassifier:\", voting_clf.predict(X_test[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bdeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# También mostramos las predicciones de cada estimador individual\n",
    "print(\"Predicciones individuales:\", [clf.predict(X_test[:1]) for clf in voting_clf.estimators_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c38551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el puntaje global del VotingClassifier\n",
    "print(\"Puntaje VotingClassifier (hard voting):\", voting_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3b66a",
   "metadata": {},
   "source": [
    "Ahora probamos con _votación suave_ (soft voting), que utiliza las probabilidades de clase en lugar de las etiquetas.  \n",
    "\n",
    "**Nota:** Para que SVC pueda estimar probabilidades, se debe habilitar el parámetro `probability=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11934372",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\"\n",
    "voting_clf.named_estimators[\"svc\"].probability = True\n",
    "voting_clf.fit(X_train, y_train)\n",
    "print(\"Puntaje VotingClassifier (soft voting):\", voting_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a575d",
   "metadata": {},
   "source": [
    "# Bagging y Pasting\n",
    "\n",
    "En esta sección se utiliza la técnica de _bagging_ (ensamblaje mediante muestreo con reemplazo) para entrenar varios árboles de decisión y combinar sus predicciones.\n",
    "\n",
    "**Resumen:** Se entrena un BaggingClassifier compuesto por 500 árboles de decisión y se visualizan las fronteras de decisión comparando un árbol individual y el ensamblaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e68a9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Se crea un BaggingClassifier con 500 estimadores, usando 100 muestras por árbol\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\n",
    "                            max_samples=100, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – esta celda genera y guarda la Figura 7–5\n",
    "def plot_decision_boundary(clf, X, y, alpha=1.0):\n",
    "    axes = [-1.5, 2.4, -1, 1.5]\n",
    "    x1, x2 = np.meshgrid(np.linspace(axes[0], axes[1], 100),\n",
    "                         np.linspace(axes[2], axes[3], 100))\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    \n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3 * alpha, cmap='Wistia')\n",
    "    plt.contour(x1, x2, y_pred, cmap=\"Greys\", alpha=0.8 * alpha)\n",
    "    colors = [\"#78785c\", \"#c47b27\"]\n",
    "    markers = (\"o\", \"^\")\n",
    "    for idx in (0, 1):\n",
    "        plt.plot(X[:, 0][y == idx], X[:, 1][y == idx],\n",
    "                 color=colors[idx], marker=markers[idx], linestyle=\"none\")\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.ylabel(r\"$x_2$\", rotation=0)\n",
    "\n",
    "# Entrenamos un árbol de decisión simple para comparación\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plot_decision_boundary(tree_clf, X_train, y_train)\n",
    "plt.title(\"Árbol de Decisión\")\n",
    "plt.sca(axes[1])\n",
    "plot_decision_boundary(bag_clf, X_train, y_train)\n",
    "plt.title(\"Árboles de Decisión con Bagging\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb348b7",
   "metadata": {},
   "source": [
    "## Evaluación Out-of-Bag (OOB)\n",
    "\n",
    "Con _bagging_ es posible evaluar el desempeño de cada árbol en los ejemplos que no fueron usados para su entrenamiento (Out-of-Bag). Esto permite obtener una estimación casi no sesgada sin necesidad de usar un conjunto de validación adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\n",
    "                            oob_score=True, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print(\"Puntaje OOB:\", bag_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d94b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestran las probabilidades OOB para las tres primeras instancias\n",
    "print(\"OOB decision function (primeras 3 instancias):\", bag_clf.oob_decision_function_[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "print(\"Precisión en el conjunto de prueba:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a8fb8",
   "metadata": {},
   "source": [
    "**Concepto importante:**  \n",
    "Al muestrear con reemplazo de un conjunto de tamaño _m_, la probabilidad de que una instancia no sea seleccionada en una extracción es 1 – 1/_m_. Si se extraen _m_ muestras, la probabilidad de que una instancia nunca se seleccione es aproximadamente exp(–1) ≈ 0.37, lo que significa que cerca del 63% de las instancias se usan en cada estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6068c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – muestra cómo se calcula la probabilidad del 63%\n",
    "print(1 - (1 - 1 / 1000) ** 1000)\n",
    "print(1 - np.exp(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5543f",
   "metadata": {},
   "source": [
    "# Bosques Aleatorios (Random Forests)\n",
    "\n",
    "Un Bosque Aleatorio es un bagging ensemble con árboles de decisión en el que se introduce aleatoriedad adicional al considerar solo un subconjunto aleatorio de características en cada división.\n",
    "\n",
    "**Resumen:** Se entrena un RandomForestClassifier y se compara su comportamiento con un BaggingClassifier configurado de forma equivalente. Se verifica que, en muchos casos, ambos producen las mismas predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49611d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,\n",
    "                                 n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c4396",
   "metadata": {},
   "source": [
    "Un Bosque Aleatorio es equivalente a un bagging de árboles de decisión con algunas restricciones adicionales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
    "    n_estimators=500, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – se verifica que las predicciones son idénticas\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred_bag = bag_clf.predict(X_test)\n",
    "print(\"¿Predicciones idénticas?\", np.all(y_pred_bag == y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd74bf",
   "metadata": {},
   "source": [
    "## Importancia de las Características (Feature Importance)\n",
    "\n",
    "Los Bosques Aleatorios pueden proporcionar una medida de la importancia de cada característica, lo que es útil para entender el modelo y para realizar selección de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d686ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(iris.data, iris.target)\n",
    "for score, name in zip(rnd_clf.feature_importances_, iris.data.columns):\n",
    "    print(round(score, 2), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeffa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – esta celda genera y guarda la Figura 7–6\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X_mnist, y_mnist = fetch_openml('mnist_784', return_X_y=True, as_frame=False,\n",
    "                                parser='auto')\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rnd_clf.fit(X_mnist, y_mnist)\n",
    "\n",
    "heatmap_image = rnd_clf.feature_importances_.reshape(28, 28)\n",
    "plt.imshow(heatmap_image, cmap=\"hot\")\n",
    "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),\n",
    "                           rnd_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['No importante', 'Muy importante'], fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8bc9e",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "En esta sección se abordan dos técnicas de boosting: AdaBoost y Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b55d1d",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "Con AdaBoost se entrenan secuencialmente modelos (por ejemplo, SVMs) y se van ponderando los ejemplos mal clasificados para enfocarse en ellos.\n",
    "\n",
    "**Resumen:** Se muestra cómo ajustar los pesos de las muestras y se generan gráficas que ilustran la evolución de las fronteras de decisión a medida que se agregan nuevos clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc299353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – esta celda genera y guarda la Figura 7–8\n",
    "m = len(X_train)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "for subplot, learning_rate in ((0, 1), (1, 0.5)):\n",
    "    sample_weights = np.ones(m) / m\n",
    "    plt.sca(axes[subplot])\n",
    "    for i in range(5):\n",
    "        svm_clf = SVC(C=0.2, gamma=0.6, random_state=42)\n",
    "        svm_clf.fit(X_train, y_train, sample_weight=sample_weights * m)\n",
    "        y_pred = svm_clf.predict(X_train)\n",
    "\n",
    "        error_weights = sample_weights[y_pred != y_train].sum()\n",
    "        r = error_weights / sample_weights.sum()  # Ecuación 7-1\n",
    "        alpha = learning_rate * np.log((1 - r) / r)  # Ecuación 7-2\n",
    "        sample_weights[y_pred != y_train] *= np.exp(alpha)  # Ecuación 7-3\n",
    "        sample_weights /= sample_weights.sum()  # Paso de normalización\n",
    "\n",
    "        plot_decision_boundary(svm_clf, X_train, y_train, alpha=0.4)\n",
    "        plt.title(f\"learning_rate = {learning_rate}\")\n",
    "    if subplot == 0:\n",
    "        plt.text(-0.75, -0.95, \"1\", fontsize=16)\n",
    "        plt.text(-1.05, -0.95, \"2\", fontsize=16)\n",
    "        plt.text(1.0, -0.95, \"3\", fontsize=16)\n",
    "        plt.text(-1.45, -0.5, \"4\", fontsize=16)\n",
    "        plt.text(1.36,  -0.95, \"5\", fontsize=16)\n",
    "    else:\n",
    "        plt.ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a907f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=30,\n",
    "    learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bca82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – para visualizar la frontera de decisión del AdaBoost classifier\n",
    "plot_decision_boundary(ada_clf, X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07698ba",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "En Gradient Boosting se ajusta un modelo en los residuos del modelo anterior. Se muestra un ejemplo con un conjunto de datos cuadrático.\n",
    "\n",
    "**Resumen:** Se entrena un primer árbol de regresión, luego se calcula el residuo (error) y se entrena un segundo árbol sobre ese residuo, y así sucesivamente. Finalmente se suman las predicciones para obtener la predicción final del ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3 * X[:, 0] ** 2 + 0.05 * np.random.randn(100)  # y = 3x² + ruido gaussiano\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e8791",
   "metadata": {},
   "source": [
    "Se entrena un segundo árbol sobre los errores residuales del primer modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=43)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se entrena un tercer árbol sobre los residuos del segundo modelo:\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=44)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93217401",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Para tres ejemplos nuevos, se suma la predicción de los tres árboles:\n",
    "X_new = np.array([[-0.4], [0.], [0.5]])\n",
    "print(\"Predicción ensemble (suma de h1, h2 y h3):\", sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – esta celda genera y guarda la Figura 7–9\n",
    "def plot_predictions(regresores, X, y, axes, style,\n",
    "                     label=None, data_style=\"b.\", data_label=None):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500)\n",
    "    y_pred = sum(regressor.predict(x1.reshape(-1, 1))\n",
    "                 for regressor in regresores)\n",
    "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
    "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
    "    if label or data_label:\n",
    "        plt.legend(loc=\"upper center\")\n",
    "    plt.axis(axes)\n",
    "\n",
    "plt.figure(figsize=(11, 11))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.2, 0.8], style=\"g-\",\n",
    "                 label=\"$h_1(x_1)$\", data_label=\"Conjunto de entrenamiento\")\n",
    "plt.ylabel(\"$y$  \", rotation=0)\n",
    "plt.title(\"Residuos y predicciones del árbol\")\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.2, 0.8], style=\"r-\",\n",
    "                 label=\"$h(x_1) = h_1(x_1)$\", data_label=\"Conjunto de entrenamiento\")\n",
    "plt.title(\"Predicción del ensemble\")\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plot_predictions([tree_reg2], X, y2, axes=[-0.5, 0.5, -0.4, 0.6], style=\"g-\",\n",
    "                 label=\"$h_2(x_1)$\", data_style=\"k+\",\n",
    "                 data_label=\"Residuos: $y - h_1(x_1)$\")\n",
    "plt.ylabel(\"$y$  \", rotation=0)\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plot_predictions([tree_reg1, tree_reg2], X, y, axes=[-0.5, 0.5, -0.2, 0.8],\n",
    "                  style=\"r-\", label=\"$h(x_1) = h_1(x_1) + h_2(x_1)$\")\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plot_predictions([tree_reg3], X, y3, axes=[-0.5, 0.5, -0.4, 0.6], style=\"g-\",\n",
    "                 label=\"$h_3(x_1)$\", data_style=\"k+\",\n",
    "                 data_label=\"Residuos: $y - h_1(x_1) - h_2(x_1)$\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$y$  \", rotation=0)\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plot_predictions([tree_reg1, tree_reg2, tree_reg3], X, y,\n",
    "                 axes=[-0.5, 0.5, -0.2, 0.8], style=\"r-\",\n",
    "                 label=\"$h(x_1) = h_1(x_1) + h_2(x_1) + h_3(x_1)$\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64e6e0",
   "metadata": {},
   "source": [
    "Ahora entrenamos un _GradientBoostingRegressor_ usando scikit-learn, tanto con un conjunto pequeño de estimadores como con uno mejor ajustado.\n",
    "\n",
    "**Resumen:** Se muestra la diferencia en el número de estimadores y la tasa de aprendizaje, que son hiperparámetros clave para evitar el sobreajuste en gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3,\n",
    "                                 learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_best = GradientBoostingRegressor(\n",
    "    max_depth=2, learning_rate=0.05, n_estimators=500,\n",
    "    n_iter_no_change=10, random_state=42)\n",
    "gbrt_best.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de estimadores en gbrt_best:\", gbrt_best.n_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a67888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – esta celda genera y guarda la Figura 7–10\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_predictions([gbrt], X, y, axes=[-0.5, 0.5, -0.1, 0.8], style=\"r-\",\n",
    "                 label=\"Predicción ensemble\")\n",
    "plt.title(f\"learning_rate={gbrt.learning_rate}, n_estimators={gbrt.n_estimators_}\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$y$\", rotation=0)\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_predictions([gbrt_best], X, y, axes=[-0.5, 0.5, -0.1, 0.8], style=\"r-\")\n",
    "plt.title(f\"learning_rate={gbrt_best.learning_rate}, n_estimators={gbrt_best.n_estimators_}\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – en este capítulo se muestra cómo cargar el conjunto de datos Housing (se presenta con más detalle en el capítulo 2)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"datasets\")\n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "housing_labels = train_set[\"median_house_value\"]\n",
    "housing = train_set.drop(\"median_house_value\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "\n",
    "hgb_reg = make_pipeline(\n",
    "    make_column_transformer((OrdinalEncoder(), [\"ocean_proximity\"]),\n",
    "                            remainder=\"passthrough\"),\n",
    "    HistGradientBoostingRegressor(categorical_features=[0], random_state=42)\n",
    ")\n",
    "hgb_reg.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118dae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código extra – se evalúa el RMSE del modelo hgb_reg usando validación cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "hgb_rmses = -cross_val_score(hgb_reg, housing, housing_labels,\n",
    "                             scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "print(pd.Series(hgb_rmses).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14a64a",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "En stacking se entrenan varios modelos base y sus predicciones se utilizan como entradas para un \"blender\" o meta-modelo final.\n",
    "\n",
    "**Resumen:** Se construye un StackingClassifier que combina las predicciones de distintos estimadores y utiliza un RandomForestClassifier como modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svc', SVC(probability=True, random_state=42))\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(random_state=43),\n",
    "    cv=5  # número de folds en validación cruzada\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puntaje StackingClassifier:\", stacking_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaed7eb",
   "metadata": {},
   "source": [
    "# Soluciones a los Ejercicios\n",
    "\n",
    "## Ejercicios 1 a 7\n",
    "\n",
    "1. Si has entrenado cinco modelos diferentes y todos logran una precisión del 95%, combinarlos en un ensemble por votación suele dar mejores resultados, sobre todo si los modelos son muy distintos.\n",
    "2. Un clasificador por votación \"hard\" cuenta los votos de cada modelo y elige la clase mayoritaria; el \"soft\" promedia las probabilidades de cada clase, dándole más peso a las predicciones con alta confianza.\n",
    "3. El bagging y el pasting pueden entrenarse en paralelo ya que cada predictor es independiente, a diferencia del boosting, donde los modelos se entrenan secuencialmente.\n",
    "4. La evaluación out-of-bag permite estimar el desempeño sin separar un conjunto de validación, aprovechando así más datos para entrenar.\n",
    "5. En un Bosque Aleatorio se selecciona un subconjunto aleatorio de características en cada división, lo que ayuda a reducir la correlación entre los árboles y a mejorar la generalización.\n",
    "6. Si AdaBoost presenta underfitting, se puede aumentar el número de estimadores, reducir la regularización del estimador base o aumentar ligeramente la tasa de aprendizaje.\n",
    "7. Si Gradient Boosting sobreajusta, se recomienda disminuir la tasa de aprendizaje o utilizar early stopping para determinar el número óptimo de predictores.\n",
    "\n",
    "## Ejercicio 8. Clasificador por Votación\n",
    "\n",
    "**Enunciado:** _Carga el conjunto de datos MNIST y divídelo en un conjunto de entrenamiento (50.000 instancias), validación (10.000) y prueba (10.000)._\n",
    "\n",
    "Dado que el dataset MNIST ya está dividido (60.000 para entrenamiento y 10.000 para prueba), solo separamos los primeros 50.000 para entrenamiento, los siguientes 10.000 para validación y los últimos 10.000 para prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace25d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_mnist[:50_000], y_mnist[:50_000]\n",
    "X_valid, y_valid = X_mnist[50_000:60_000], y_mnist[50_000:60_000]\n",
    "X_test, y_test = X_mnist[60_000:], y_mnist[60_000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3439023",
   "metadata": {},
   "source": [
    "**Enunciado:** _Luego, entrena varios clasificadores, como un Random Forest, un Extra-Trees y un SVM._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3907f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae1939",
   "metadata": {},
   "source": [
    "**Nota:** En `LinearSVC` se establece explícitamente el parámetro `dual=True` para mantener la consistencia en la salida (consulta la documentación para más detalles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = LinearSVC(max_iter=100, tol=20, dual=True, random_state=42)\n",
    "mlp_clf = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2019b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Entrenando:\", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puntajes en el conjunto de validación:\")\n",
    "print([estimator.score(X_valid, y_valid) for estimator in estimators])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c32227",
   "metadata": {},
   "source": [
    "Se observa que el SVM lineal rinde peor que los otros clasificadores; sin embargo, se mantendrá en el ensemble para ver su efecto en la votación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca341e3",
   "metadata": {},
   "source": [
    "**Enunciado:** _Combina los clasificadores en un ensemble (VotingClassifier) y evalúa su desempeño en el conjunto de validación. Prueba con votación suave y dura._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03855715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"svm_clf\", svm_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(named_estimators)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Puntaje VotingClassifier (validación):\", voting_clf.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d527876",
   "metadata": {},
   "source": [
    "**Aviso:**  \n",
    "El VotingClassifier hace clones de cada clasificador y utiliza índices de clase para entrenarlos. Si es necesario, se puede utilizar un LabelEncoder para convertir las clases, pero en el caso de MNIST basta con convertir a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_valid_encoded = encoder.fit_transform(y_valid)\n",
    "# En MNIST, los dígitos ya coinciden con los índices, así que:\n",
    "y_valid_encoded = y_valid.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527433f",
   "metadata": {},
   "source": [
    "Se evalúan los clones de los clasificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459fbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puntajes de los clasificadores clonados en VotingClassifier:\")\n",
    "print([estimator.score(X_valid, y_valid_encoded) for estimator in voting_clf.estimators_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34fb6e",
   "metadata": {},
   "source": [
    "Se procede a eliminar el SVM, que afecta negativamente al desempeño. Esto se hace ajustando los parámetros del VotingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.set_params(svm_clf=\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c68cdc",
   "metadata": {},
   "source": [
    "Aunque la lista de estimadores se actualiza, la lista de entrenados no lo hace, por lo que se elimina el estimador SVM de ambas listas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8739ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_trained = voting_clf.named_estimators_.pop(\"svm_clf\")\n",
    "voting_clf.estimators_.remove(svm_clf_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efef6d",
   "metadata": {},
   "source": [
    "Se vuelve a evaluar el VotingClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puntaje VotingClassifier (sin SVM):\", voting_clf.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1f358",
   "metadata": {},
   "source": [
    "Ahora se prueba con votación suave. Basta con cambiar el atributo `voting`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968abd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\"\n",
    "print(\"Puntaje VotingClassifier (soft voting):\", voting_clf.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb658b",
   "metadata": {},
   "source": [
    "En este caso, la votación dura (hard voting) rinde mejor. Se evalúa en el conjunto de prueba y se comparan los puntajes de los clasificadores individuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783aa81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = \"hard\"\n",
    "print(\"Puntaje VotingClassifier en el conjunto de prueba:\", voting_clf.score(X_test, y_test))\n",
    "print(\"Puntajes individuales en el conjunto de prueba:\",\n",
    "      [estimator.score(X_test, y_test.astype(np.int64)) for estimator in voting_clf.estimators_])\n",
    "#\n",
    "# Se observa que el VotingClassifier reduce la tasa de error del mejor modelo de aproximadamente 3% a 2.7%, es decir, se producen cerca de un 10% menos de errores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f2b671",
   "metadata": {},
   "source": [
    "## Ejercicio 9. Ensemble de Stacking\n",
    "\n",
    "**Enunciado:** _Utiliza los clasificadores individuales para hacer predicciones en el conjunto de validación y crea un nuevo conjunto de entrenamiento, donde cada instancia es un vector con las predicciones de cada modelo y la etiqueta es la clase original. Entrena un clasificador (blender) sobre este nuevo conjunto._\n",
    "\n",
    "Se recogen las predicciones de cada modelo en el conjunto de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efffb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_predictions = np.empty((len(X_valid), len(estimators)), dtype=object)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_valid_predictions[:, index] = estimator.predict(X_valid)\n",
    "\n",
    "print(\"Predicciones del conjunto de validación (stacking):\")\n",
    "print(X_valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se entrena un \"blender\" usando un RandomForestClassifier\n",
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True,\n",
    "                                            random_state=42)\n",
    "rnd_forest_blender.fit(X_valid_predictions, y_valid)\n",
    "\n",
    "print(\"Puntaje OOB del blender:\", rnd_forest_blender.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d53ba8d",
   "metadata": {},
   "source": [
    "_En adelante, se evalúa el ensemble de stacking en el conjunto de prueba: para cada imagen se recogen las predicciones de cada clasificador y se alimenta el blender para obtener la predicción final._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af36a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=object)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "\n",
    "y_pred = rnd_forest_blender.predict(X_test_predictions)\n",
    "print(\"Precisión del ensemble de stacking:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f391e4b",
   "metadata": {},
   "source": [
    "En este ejemplo el ensemble de stacking no supera el desempeño del VotingClassifier.\n",
    "\n",
    "**Ejercicio adicional:** _Vuelve a intentarlo utilizando StackingClassifier y compáralo con el VotingClassifier._\n",
    "\n",
    "Como el StackingClassifier de scikit-learn usa validación cruzada, no es necesario disponer de un conjunto de validación separado. Se unen los conjuntos de entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, y_train_full = X_mnist[:60_000], y_mnist[:60_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ba146",
   "metadata": {},
   "source": [
    "Se crea y entrena el StackingClassifier sobre el conjunto completo de entrenamiento.\n",
    "\n",
    "**Advertencia:** La siguiente celda puede tardar entre 15 y 30 minutos en ejecutarse, ya que entrena los clasificadores con 5 folds de validación cruzada (es decir, 25 modelos en total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_clf = StackingClassifier(named_estimators,\n",
    "                               final_estimator=rnd_forest_blender)\n",
    "stack_clf.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acdb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puntaje StackingClassifier en el conjunto de prueba:\", stack_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1cadf",
   "metadata": {},
   "source": [
    "**Resumen final:**  \n",
    "El StackingClassifier obtuvo un desempeño significativamente mejor que la implementación de stacking manual. Esto se debe a dos factores principales:\n",
    "\n",
    "* Al disponer de más datos (se reubicó el conjunto de validación), el modelo final se entrenó con más información.\n",
    "* El StackingClassifier utiliza `predict_proba()` o `decision_function()` (cuando están disponibles), proporcionando al blender entradas más precisas para la combinación final.\n",
    "\n",
    "¡Y con esto se concluye el capítulo! Felicidades por terminar el capítulo y los ejercicios."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
