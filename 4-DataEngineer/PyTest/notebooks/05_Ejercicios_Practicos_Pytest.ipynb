{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Prácticos de Pytest para Data Engineering\n",
    "\n",
    "En este notebook, encontrarás una serie de ejercicios prácticos para aplicar lo que has aprendido sobre pytest en el contexto de Data Engineering. Estos ejercicios están diseñados para reforzar los conceptos y técnicas presentados en los notebooks anteriores.\n",
    "\n",
    "Utilizaremos el dataset de ventas de productos que hemos estado usando a lo largo del tutorial. Cada ejercicio incluye instrucciones detalladas y, en algunos casos, código inicial para ayudarte a comenzar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración Inicial\n",
    "\n",
    "Primero, vamos a importar las bibliotecas necesarias y cargar nuestro dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Cargamos el dataset\n",
    "df_ventas = pd.read_csv('../data/ventas_productos.csv')\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "df_ventas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Testing de una Función de Análisis de Rentabilidad\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que calcule la rentabilidad de cada producto en el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "La rentabilidad se define como: `(precio * cantidad * (1 - descuento)) / (precio * cantidad) * 100`\n",
    "\n",
    "Es decir, el porcentaje del ingreso potencial que realmente se obtuvo después de aplicar descuentos.\n",
    "\n",
    "### Tarea 1: Implementa la función `calcular_rentabilidad`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calcular_rentabilidad(df):\n",
    "    \"\"\"Calcula la rentabilidad de cada producto en el dataset de ventas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'precio', 'cantidad', 'descuento' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame original con una columna adicional 'rentabilidad' (en porcentaje)\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    # Recuerda: rentabilidad = (precio * cantidad * (1 - descuento)) / (precio * cantidad) * 100\n",
    "    \n",
    "    # Sugerencia: Crea una copia del DataFrame para no modificar el original\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Calcula la rentabilidad\n",
    "    # ...\n",
    "    \n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `calcular_rentabilidad`\n",
    "\n",
    "Escribe al menos tres tests para verificar que la función `calcular_rentabilidad` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función añada la columna 'rentabilidad' al DataFrame\n",
    "2. Que los valores de rentabilidad sean correctos para algunos casos específicos\n",
    "3. Que la función maneje correctamente casos especiales (por ejemplo, descuento = 0)\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%file test_rentabilidad.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calcular_rentabilidad(df):\n",
    "    \"\"\"Calcula la rentabilidad de cada producto en el dataset de ventas.\"\"\"\n",
    "    df_resultado = df.copy()\n",
    "    df_resultado['rentabilidad'] = (1 - df_resultado['descuento']) * 100\n",
    "    return df_resultado\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'producto': ['Producto A', 'Producto B', 'Producto C'],\n",
    "        'precio': [100.0, 200.0, 300.0],\n",
    "        'cantidad': [2, 1, 3],\n",
    "        'descuento': [0.1, 0.0, 0.25],\n",
    "        'total': [180.0, 200.0, 675.0]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Escribe tus tests aquí\n",
    "def test_columna_rentabilidad_existe():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_valores_rentabilidad_correctos():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_caso_descuento_cero():\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `calcular_rentabilidad` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_rentabilidad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Testing de una Función de Detección de Anomalías\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que detecte anomalías en el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "Una anomalía se define como un valor que está más de 2 desviaciones estándar por encima o por debajo de la media de una columna numérica.\n",
    "\n",
    "### Tarea 1: Implementa la función `detectar_anomalias`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detectar_anomalias(df, columna, umbral=2.0):\n",
    "    \"\"\"Detecta anomalías en una columna numérica del DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con la columna a analizar\n",
    "        columna: Nombre de la columna numérica a analizar\n",
    "        umbral: Número de desviaciones estándar para considerar un valor como anomalía\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con las filas que contienen anomalías\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    # Recuerda: Una anomalía es un valor que está más de 'umbral' desviaciones estándar\n",
    "    # por encima o por debajo de la media\n",
    "    \n",
    "    # Calcula la media y la desviación estándar\n",
    "    # ...\n",
    "    \n",
    "    # Identifica las anomalías\n",
    "    # ...\n",
    "    \n",
    "    return df_anomalias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `detectar_anomalias`\n",
    "\n",
    "Escribe al menos tres tests para verificar que la función `detectar_anomalias` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función detecte correctamente anomalías por encima de la media\n",
    "2. Que la función detecte correctamente anomalías por debajo de la media\n",
    "3. Que la función maneje correctamente diferentes valores de umbral\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%file test_anomalias.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detectar_anomalias(df, columna, umbral=2.0):\n",
    "    \"\"\"Detecta anomalías en una columna numérica del DataFrame.\"\"\"\n",
    "    # Calcula la media y la desviación estándar\n",
    "    media = df[columna].mean()\n",
    "    desv_std = df[columna].std()\n",
    "    \n",
    "    # Identifica las anomalías\n",
    "    limite_superior = media + umbral * desv_std\n",
    "    limite_inferior = media - umbral * desv_std\n",
    "    \n",
    "    # Filtra las filas con anomalías\n",
    "    anomalias = df[(df[columna] > limite_superior) | (df[columna] < limite_inferior)]\n",
    "    \n",
    "    return anomalias\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba con valores normales y anómalos.\"\"\"\n",
    "    # Crea un DataFrame con valores normales (alrededor de 100) y algunos valores anómalos\n",
    "    np.random.seed(42)  # Para reproducibilidad\n",
    "    valores_normales = np.random.normal(100, 10, 20)  # 20 valores normales con media 100 y desv. std. 10\n",
    "    valores_anomalos_altos = [150, 160]  # Anomalías por encima (> media + 2*desv_std = 100 + 2*10 = 120)\n",
    "    valores_anomalos_bajos = [60, 50]  # Anomalías por debajo (< media - 2*desv_std = 100 - 2*10 = 80)\n",
    "    \n",
    "    valores = np.concatenate([valores_normales, valores_anomalos_altos, valores_anomalos_bajos])\n",
    "    ids = range(1, len(valores) + 1)\n",
    "    \n",
    "    return pd.DataFrame({'id': ids, 'valor': valores})\n",
    "\n",
    "# Escribe tus tests aquí\n",
    "def test_detecta_anomalias_por_encima():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_detecta_anomalias_por_debajo():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_umbral_diferente():\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `detectar_anomalias` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_anomalias.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Testing de una Función de Segmentación de Clientes\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que segmente los productos en el dataset de ventas según su precio y popularidad, y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "### Tarea 1: Implementa la función `segmentar_productos`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def segmentar_productos(df):\n",
    "    \"\"\"Segmenta los productos según su precio y popularidad (cantidad vendida).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'producto', 'precio' y 'cantidad'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con los productos segmentados\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    # Segmentación por precio:\n",
    "    # - Económico: precio < 50\n",
    "    # - Estándar: 50 <= precio < 100\n",
    "    # - Premium: 100 <= precio < 200\n",
    "    # - Lujo: precio >= 200\n",
    "    #\n",
    "    # Segmentación por popularidad (cantidad total vendida):\n",
    "    # - Baja: cantidad < 2\n",
    "    # - Media: 2 <= cantidad < 4\n",
    "    # - Alta: cantidad >= 4\n",
    "    \n",
    "    # Agrupa por producto y suma las cantidades\n",
    "    # ...\n",
    "    \n",
    "    # Aplica la segmentación\n",
    "    # ...\n",
    "    \n",
    "    return df_segmentado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `segmentar_productos`\n",
    "\n",
    "Escribe al menos tres tests para verificar que la función `segmentar_productos` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función segmente correctamente por precio\n",
    "2. Que la función segmente correctamente por popularidad\n",
    "3. Que la función maneje correctamente productos con múltiples ventas\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%file test_segmentacion.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def segmentar_productos(df):\n",
    "    \"\"\"Segmenta los productos según su precio y popularidad (cantidad vendida).\"\"\"\n",
    "    # Agrupa por producto y calcula el precio promedio y la cantidad total\n",
    "    df_agrupado = df.groupby('producto').agg({\n",
    "        'precio': 'mean',\n",
    "        'cantidad': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Segmentación por precio\n",
    "    condiciones_precio = [\n",
    "        (df_agrupado['precio'] < 50),\n",
    "        (df_agrupado['precio'] >= 50) & (df_agrupado['precio'] < 100),\n",
    "        (df_agrupado['precio'] >= 100) & (df_agrupado['precio'] < 200),\n",
    "        (df_agrupado['precio'] >= 200)\n",
    "    ]\n",
    "    categorias_precio = ['Económico', 'Estándar', 'Premium', 'Lujo']\n",
    "    df_agrupado['segmento_precio'] = np.select(condiciones_precio, categorias_precio, default='Sin categoría')\n",
    "    \n",
    "    # Segmentación por popularidad\n",
    "    condiciones_popularidad = [\n",
    "        (df_agrupado['cantidad'] < 2),\n",
    "        (df_agrupado['cantidad'] >= 2) & (df_agrupado['cantidad'] < 4),\n",
    "        (df_agrupado['cantidad'] >= 4)\n",
    "    ]\n",
    "    categorias_popularidad = ['Baja', 'Media', 'Alta']\n",
    "    df_agrupado['segmento_popularidad'] = np.select(condiciones_popularidad, categorias_popularidad, default='Sin categoría')\n",
    "    \n",
    "    return df_agrupado\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba con diferentes productos.\"\"\"\n",
    "    data = {\n",
    "        'producto': ['Producto A', 'Producto A', 'Producto B', 'Producto C', 'Producto D', 'Producto E'],\n",
    "        'precio': [30.0, 30.0, 75.0, 150.0, 250.0, 50.0],\n",
    "        'cantidad': [1, 2, 2, 3, 1, 5]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Escribe tus tests aquí\n",
    "def test_segmentacion_por_precio():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_segmentacion_por_popularidad():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_productos_multiples_ventas():\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `segmentar_productos` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_segmentacion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Testing de un Pipeline de Preprocesamiento\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás un pipeline de preprocesamiento para el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "### Tarea 1: Implementa la clase `PipelinePreprocesamiento`\n",
    "\n",
    "Completa la siguiente clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PipelinePreprocesamiento:\n",
    "    \"\"\"Pipeline de preprocesamiento para el dataset de ventas.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el pipeline.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def convertir_tipos(self, df):\n",
    "        \"\"\"Convierte las columnas a los tipos de datos correctos.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a procesar\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: DataFrame con los tipos de datos convertidos\n",
    "        \"\"\"\n",
    "        # Tu código aquí\n",
    "        # Convierte 'fecha' a datetime, 'precio', 'descuento' y 'total' a float, 'cantidad' a int\n",
    "        \n",
    "        return df_convertido\n",
    "    \n",
    "    def eliminar_duplicados(self, df):\n",
    "        \"\"\"Elimina filas duplicadas del DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a procesar\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: DataFrame sin duplicados\n",
    "        \"\"\"\n",
    "        # Tu código aquí\n",
    "        \n",
    "        return df_sin_duplicados\n",
    "    \n",
    "    def normalizar_categorias(self, df):\n",
    "        \"\"\"Normaliza las categorías (primera letra mayúscula, resto minúsculas).\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a procesar\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: DataFrame con categorías normalizadas\n",
    "        \"\"\"\n",
    "        # Tu código aquí\n",
    "        \n",
    "        return df_normalizado\n",
    "    \n",
    "    def procesar(self, df):\n",
    "        \"\"\"Aplica todo el pipeline de preprocesamiento.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a procesar\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: DataFrame procesado\n",
    "        \"\"\"\n",
    "        # Tu código aquí\n",
    "        # Aplica todas las transformaciones en secuencia\n",
    "        \n",
    "        return df_procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la clase `PipelinePreprocesamiento`\n",
    "\n",
    "Escribe tests para verificar que cada método de la clase `PipelinePreprocesamiento` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que `convertir_tipos` convierta correctamente los tipos de datos\n",
    "2. Que `eliminar_duplicados` elimine correctamente las filas duplicadas\n",
    "3. Que `normalizar_categorias` normalice correctamente las categorías\n",
    "4. Que `procesar` aplique correctamente todas las transformaciones\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%file test_pipeline_preprocesamiento.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PipelinePreprocesamiento:\n",
    "    \"\"\"Pipeline de preprocesamiento para el dataset de ventas.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el pipeline.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def convertir_tipos(self, df):\n",
    "        \"\"\"Convierte las columnas a los tipos de datos correctos.\"\"\"\n",
    "        df_convertido = df.copy()\n",
    "        df_convertido['fecha'] = pd.to_datetime(df_convertido['fecha'])\n",
    "        df_convertido['precio'] = pd.to_numeric(df_convertido['precio'])\n",
    "        df_convertido['cantidad'] = pd.to_numeric(df_convertido['cantidad']).astype(int)\n",
    "        df_convertido['descuento'] = pd.to_numeric(df_convertido['descuento'])\n",
    "        df_convertido['total'] = pd.to_numeric(df_convertido['total'])\n",
    "        return df_convertido\n",
    "    \n",
    "    def eliminar_duplicados(self, df):\n",
    "        \"\"\"Elimina filas duplicadas del DataFrame.\"\"\"\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "    def normalizar_categorias(self, df):\n",
    "        \"\"\"Normaliza las categorías (primera letra mayúscula, resto minúsculas).\"\"\"\n",
    "        df_normalizado = df.copy()\n",
    "        df_normalizado['categoria'] = df_normalizado['categoria'].str.capitalize()\n",
    "        return df_normalizado\n",
    "    \n",
    "    def procesar(self, df):\n",
    "        \"\"\"Aplica todo el pipeline de preprocesamiento.\"\"\"\n",
    "        df_procesado = df.copy()\n",
    "        df_procesado = self.convertir_tipos(df_procesado)\n",
    "        df_procesado = self.eliminar_duplicados(df_procesado)\n",
    "        df_procesado = self.normalizar_categorias(df_procesado)\n",
    "        return df_procesado\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba con problemas para preprocesar.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3, 3],  # ID duplicado\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech', 'Teclado Logitech'],\n",
    "        'categoria': ['ELECTRÓNICA', 'electrónica', 'Accesorios', 'accesorios'],  # Inconsistencia en mayúsculas/minúsculas\n",
    "        'precio': ['899.99', '249.99', '59.99', '59.99'],  # Strings en lugar de float\n",
    "        'cantidad': ['1', '2', '3', '3'],  # Strings en lugar de int\n",
    "        'descuento': [0.05, 0.00, 0.10, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Escribe tus tests aquí\n",
    "def test_convertir_tipos():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_eliminar_duplicados():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_normalizar_categorias():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_procesar():\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la clase `PipelinePreprocesamiento` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_pipeline_preprocesamiento.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Testing de una Función de Validación de Datos\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que valide la calidad de los datos en el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "### Tarea 1: Implementa la función `validar_calidad_datos`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def validar_calidad_datos(df):\n",
    "    \"\"\"Valida la calidad de los datos en el dataset de ventas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    # Realiza las siguientes validaciones:\n",
    "    # 1. Completitud: No debe haber valores nulos\n",
    "    # 2. Consistencia: El total debe ser aproximadamente igual a precio * cantidad * (1 - descuento)\n",
    "    # 3. Validez: Los precios, cantidades y totales deben ser positivos\n",
    "    # 4. Validez: Los descuentos deben estar entre 0 y 1\n",
    "    \n",
    "    resultados = {\n",
    "        'completitud': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'consistencia': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'validez': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Implementa las validaciones\n",
    "    # ...\n",
    "    \n",
    "    # Determina si el DataFrame es válido en general\n",
    "    resultados['valido'] = (\n",
    "        resultados['completitud']['valido'] and\n",
    "        resultados['consistencia']['valido'] and\n",
    "        resultados['validez']['valido']\n",
    "    )\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `validar_calidad_datos`\n",
    "\n",
    "Escribe tests para verificar que la función `validar_calidad_datos` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función detecte correctamente valores nulos\n",
    "2. Que la función detecte correctamente inconsistencias en los totales\n",
    "3. Que la función detecte correctamente valores inválidos (negativos o descuentos fuera de rango)\n",
    "4. Que la función valide correctamente un DataFrame sin problemas\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%file test_validacion_calidad.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def validar_calidad_datos(df):\n",
    "    \"\"\"Valida la calidad de los datos en el dataset de ventas.\"\"\"\n",
    "    resultados = {\n",
    "        'completitud': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'consistencia': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'validez': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 1. Completitud: No debe haber valores nulos\n",
    "    nulos_por_columna = df.isnull().sum()\n",
    "    columnas_con_nulos = nulos_por_columna[nulos_por_columna > 0]\n",
    "    \n",
    "    if not columnas_con_nulos.empty:\n",
    "        resultados['completitud']['valido'] = False\n",
    "        resultados['completitud']['detalles'] = columnas_con_nulos.to_dict()\n",
    "    \n",
    "    # 2. Consistencia: El total debe ser aproximadamente igual a precio * cantidad * (1 - descuento)\n",
    "    df_temp = df.copy()\n",
    "    df_temp['total_calculado'] = df_temp['precio'] * df_temp['cantidad'] * (1 - df_temp['descuento'])\n",
    "    df_temp['diferencia'] = abs(df_temp['total'] - df_temp['total_calculado'])\n",
    "    inconsistencias = df_temp[df_temp['diferencia'] > 0.01]\n",
    "    \n",
    "    if not inconsistencias.empty:\n",
    "        resultados['consistencia']['valido'] = False\n",
    "        resultados['consistencia']['detalles'] = {\n",
    "            'filas_inconsistentes': len(inconsistencias),\n",
    "            'ids': inconsistencias['id'].tolist()\n",
    "        }\n",
    "    \n",
    "    # 3. Validez: Los precios, cantidades y totales deben ser positivos\n",
    "    valores_negativos = {}\n",
    "    for columna in ['precio', 'cantidad', 'total']:\n",
    "        negativos = df[df[columna] < 0]\n",
    "        if not negativos.empty:\n",
    "            valores_negativos[columna] = len(negativos)\n",
    "    \n",
    "    # 4. Validez: Los descuentos deben estar entre 0 y 1\n",
    "    descuentos_invalidos = df[(df['descuento'] < 0) | (df['descuento'] > 1)]\n",
    "    if not descuentos_invalidos.empty:\n",
    "        valores_negativos['descuento'] = len(descuentos_invalidos)\n",
    "    \n",
    "    if valores_negativos:\n",
    "        resultados['validez']['valido'] = False\n",
    "        resultados['validez']['detalles'] = valores_negativos\n",
    "    \n",
    "    # Determina si el DataFrame es válido en general\n",
    "    resultados['valido'] = (\n",
    "        resultados['completitud']['valido'] and\n",
    "        resultados['consistencia']['valido'] and\n",
    "        resultados['validez']['valido']\n",
    "    )\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "@pytest.fixture\n",
    "def df_valido():\n",
    "    \"\"\"Fixture que crea un DataFrame válido.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_con_nulos():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores nulos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', None, '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', None],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_inconsistente():\n",
    "    \"\"\"Fixture que crea un DataFrame con totales inconsistentes.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 600.00, 161.97]  # El total para el Monitor Dell debería ser 499.98\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_invalido():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores inválidos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, -249.99, 59.99],  # Precio negativo\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 1.5],  # Descuento mayor a 1\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Escribe tus tests aquí\n",
    "def test_validar_df_valido():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_validar_df_con_nulos():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_validar_df_inconsistente():\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "def test_validar_df_invalido():\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `validar_calidad_datos` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_validacion_calidad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soluciones\n",
    "\n",
    "A continuación, se presentan las soluciones a los ejercicios anteriores. Intenta resolver los ejercicios por tu cuenta antes de mirar las soluciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 1: Testing de una Función de Análisis de Rentabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calcular_rentabilidad(df):\n",
    "    \"\"\"Calcula la rentabilidad de cada producto en el dataset de ventas.\"\"\"\n",
    "    df_resultado = df.copy()\n",
    "    df_resultado['rentabilidad'] = (1 - df_resultado['descuento']) * 100\n",
    "    return df_resultado\n",
    "\n",
    "# Tests\n",
    "def test_columna_rentabilidad_existe(df_test):\n",
    "    resultado = calcular_rentabilidad(df_test)\n",
    "    assert 'rentabilidad' in resultado.columns\n",
    "\n",
    "def test_valores_rentabilidad_correctos(df_test):\n",
    "    resultado = calcular_rentabilidad(df_test)\n",
    "    # Producto A: descuento = 0.1, rentabilidad = (1 - 0.1) * 100 = 90%\n",
    "    assert resultado.loc[0, 'rentabilidad'] == 90.0\n",
    "    # Producto B: descuento = 0.0, rentabilidad = (1 - 0.0) * 100 = 100%\n",
    "    assert resultado.loc[1, 'rentabilidad'] == 100.0\n",
    "    # Producto C: descuento = 0.25, rentabilidad = (1 - 0.25) * 100 = 75%\n",
    "    assert resultado.loc[2, 'rentabilidad'] == 75.0\n",
    "\n",
    "def test_caso_descuento_cero(df_test):\n",
    "    # Creamos un DataFrame con descuento cero\n",
    "    df_descuento_cero = df_test.copy()\n",
    "    df_descuento_cero['descuento'] = 0.0\n",
    "    \n",
    "    resultado = calcular_rentabilidad(df_descuento_cero)\n",
    "    \n",
    "    # Todos los productos deberían tener rentabilidad 100%\n",
    "    assert (resultado['rentabilidad'] == 100.0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 2: Testing de una Función de Detección de Anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detectar_anomalias(df, columna, umbral=2.0):\n",
    "    \"\"\"Detecta anomalías en una columna numérica del DataFrame.\"\"\"\n",
    "    # Calcula la media y la desviación estándar\n",
    "    media = df[columna].mean()\n",
    "    desv_std = df[columna].std()\n",
    "    \n",
    "    # Identifica las anomalías\n",
    "    limite_superior = media + umbral * desv_std\n",
    "    limite_inferior = media - umbral * desv_std\n",
    "    \n",
    "    # Filtra las filas con anomalías\n",
    "    anomalias = df[(df[columna] > limite_superior) | (df[columna] < limite_inferior)]\n",
    "    \n",
    "    return anomalias\n",
    "\n",
    "# Tests\n",
    "def test_detecta_anomalias_por_encima(df_test):\n",
    "    anomalias = detectar_anomalias(df_test, 'valor')\n",
    "    \n",
    "    # Verificamos que se detecten las anomalías por encima\n",
    "    assert len(anomalias) == 4  # 2 anomalías por encima y 2 por debajo\n",
    "    assert 150 in anomalias['valor'].values\n",
    "    assert 160 in anomalias['valor'].values\n",
    "\n",
    "def test_detecta_anomalias_por_debajo(df_test):\n",
    "    anomalias = detectar_anomalias(df_test, 'valor')\n",
    "    \n",
    "    # Verificamos que se detecten las anomalías por debajo\n",
    "    assert 60 in anomalias['valor'].values\n",
    "    assert 50 in anomalias['valor'].values\n",
    "\n",
    "def test_umbral_diferente(df_test):\n",
    "    # Con umbral = 1.0, deberíamos detectar más anomalías\n",
    "    anomalias_umbral_1 = detectar_anomalias(df_test, 'valor', umbral=1.0)\n",
    "    \n",
    "    # Con umbral = 3.0, deberíamos detectar menos anomalías\n",
    "    anomalias_umbral_3 = detectar_anomalias(df_test, 'valor', umbral=3.0)\n",
    "    \n",
    "    assert len(anomalias_umbral_1) > len(anomalias_umbral_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 3: Testing de una Función de Segmentación de Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def segmentar_productos(df):\n",
    "    \"\"\"Segmenta los productos según su precio y popularidad (cantidad vendida).\"\"\"\n",
    "    # Agrupa por producto y calcula el precio promedio y la cantidad total\n",
    "    df_agrupado = df.groupby('producto').agg({\n",
    "        'precio': 'mean',\n",
    "        'cantidad': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Segmentación por precio\n",
    "    condiciones_precio = [\n",
    "        (df_agrupado['precio'] < 50),\n",
    "        (df_agrupado['precio'] >= 50) & (df_agrupado['precio'] < 100),\n",
    "        (df_agrupado['precio'] >= 100) & (df_agrupado['precio'] < 200),\n",
    "        (df_agrupado['precio'] >= 200)\n",
    "    ]\n",
    "    categorias_precio = ['Económico', 'Estándar', 'Premium', 'Lujo']\n",
    "    df_agrupado['segmento_precio'] = np.select(condiciones_precio, categorias_precio, default='Sin categoría')\n",
    "    \n",
    "    # Segmentación por popularidad\n",
    "    condiciones_popularidad = [\n",
    "        (df_agrupado['cantidad'] < 2),\n",
    "        (df_agrupado['cantidad'] >= 2) & (df_agrupado['cantidad'] < 4),\n",
    "        (df_agrupado['cantidad'] >= 4)\n",
    "    ]\n",
    "    categorias_popularidad = ['Baja', 'Media', 'Alta']\n",
    "    df_agrupado['segmento_popularidad'] = np.select(condiciones_popularidad, categorias_popularidad, default='Sin categoría')\n",
    "    \n",
    "    return df_agrupado\n",
    "\n",
    "# Tests\n",
    "def test_segmentacion_por_precio(df_test):\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    \n",
    "    # Verificamos la segmentación por precio\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto A', 'segmento_precio'].iloc[0] == 'Económico'  # 30.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto B', 'segmento_precio'].iloc[0] == 'Estándar'  # 75.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto C', 'segmento_precio'].iloc[0] == 'Premium'  # 150.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto D', 'segmento_precio'].iloc[0] == 'Lujo'  # 250.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto E', 'segmento_precio'].iloc[0] == 'Estándar'  # 50.0\n",
    "\n",
    "def test_segmentacion_por_popularidad(df_test):\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    \n",
    "    # Verificamos la segmentación por popularidad\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto A', 'segmento_popularidad'].iloc[0] == 'Media'  # 3\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto B', 'segmento_popularidad'].iloc[0] == 'Media'  # 2\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto C', 'segmento_popularidad'].iloc[0] == 'Media'  # 3\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto D', 'segmento_popularidad'].iloc[0] == 'Baja'  # 1\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto E', 'segmento_popularidad'].iloc[0] == 'Alta'  # 5\n",
    "\n",
    "def test_productos_multiples_ventas(df_test):\n",
    "    # Verificamos que el Producto A, que tiene múltiples ventas, se haya agregado correctamente\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    \n",
    "    # Debe haber una sola fila para el Producto A\n",
    "    assert len(resultado[resultado['producto'] == 'Producto A']) == 1\n",
    "    \n",
    "    # La cantidad debe ser la suma de todas las ventas (1 + 2 = 3)\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto A', 'cantidad'].iloc[0] == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 4: Testing de un Pipeline de Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PipelinePreprocesamiento:\n",
    "    \"\"\"Pipeline de preprocesamiento para el dataset de ventas.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el pipeline.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def convertir_tipos(self, df):\n",
    "        \"\"\"Convierte las columnas a los tipos de datos correctos.\"\"\"\n",
    "        df_convertido = df.copy()\n",
    "        df_convertido['fecha'] = pd.to_datetime(df_convertido['fecha'])\n",
    "        df_convertido['precio'] = pd.to_numeric(df_convertido['precio'])\n",
    "        df_convertido['cantidad'] = pd.to_numeric(df_convertido['cantidad']).astype(int)\n",
    "        df_convertido['descuento'] = pd.to_numeric(df_convertido['descuento'])\n",
    "        df_convertido['total'] = pd.to_numeric(df_convertido['total'])\n",
    "        return df_convertido\n",
    "    \n",
    "    def eliminar_duplicados(self, df):\n",
    "        \"\"\"Elimina filas duplicadas del DataFrame.\"\"\"\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "    def normalizar_categorias(self, df):\n",
    "        \"\"\"Normaliza las categorías (primera letra mayúscula, resto minúsculas).\"\"\"\n",
    "        df_normalizado = df.copy()\n",
    "        df_normalizado['categoria'] = df_normalizado['categoria'].str.capitalize()\n",
    "        return df_normalizado\n",
    "    \n",
    "    def procesar(self, df):\n",
    "        \"\"\"Aplica todo el pipeline de preprocesamiento.\"\"\"\n",
    "        df_procesado = df.copy()\n",
    "        df_procesado = self.convertir_tipos(df_procesado)\n",
    "        df_procesado = self.eliminar_duplicados(df_procesado)\n",
    "        df_procesado = self.normalizar_categorias(df_procesado)\n",
    "        return df_procesado\n",
    "\n",
    "# Tests\n",
    "def test_convertir_tipos(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.convertir_tipos(df_test)\n",
    "    \n",
    "    # Verificamos los tipos de datos\n",
    "    assert pd.api.types.is_datetime64_dtype(resultado['fecha'])\n",
    "    assert pd.api.types.is_float_dtype(resultado['precio'])\n",
    "    assert pd.api.types.is_integer_dtype(resultado['cantidad'])\n",
    "    assert pd.api.types.is_float_dtype(resultado['descuento'])\n",
    "    assert pd.api.types.is_float_dtype(resultado['total'])\n",
    "\n",
    "def test_eliminar_duplicados(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.eliminar_duplicados(df_test)\n",
    "    \n",
    "    # Verificamos que se hayan eliminado los duplicados\n",
    "    assert len(resultado) == 3  # El DataFrame original tiene 4 filas, una duplicada\n",
    "    assert resultado['id'].nunique() == 3  # Debe haber 3 IDs únicos\n",
    "\n",
    "def test_normalizar_categorias(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.normalizar_categorias(df_test)\n",
    "    \n",
    "    # Verificamos que las categorías estén normalizadas\n",
    "    assert resultado['categoria'].iloc[0] == 'Electrónica'  # ELECTRÓNICA -> Electrónica\n",
    "    assert resultado['categoria'].iloc[1] == 'Electrónica'  # electrónica -> Electrónica\n",
    "    assert resultado['categoria'].iloc[2] == 'Accesorios'  # Accesorios -> Accesorios\n",
    "    assert resultado['categoria'].iloc[3] == 'Accesorios'  # accesorios -> Accesorios\n",
    "\n",
    "def test_procesar(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.procesar(df_test)\n",
    "    \n",
    "    # Verificamos que se hayan aplicado todas las transformaciones\n",
    "    assert len(resultado) == 3  # Eliminación de duplicados\n",
    "    assert pd.api.types.is_datetime64_dtype(resultado['fecha'])  # Conversión de tipos\n",
    "    assert resultado['categoria'].iloc[0] == 'Electrónica'  # Normalización de categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 5: Testing de una Función de Validación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def validar_calidad_datos(df):\n",
    "    \"\"\"Valida la calidad de los datos en el dataset de ventas.\"\"\"\n",
    "    resultados = {\n",
    "        'completitud': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'consistencia': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'validez': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 1. Completitud: No debe haber valores nulos\n",
    "    nulos_por_columna = df.isnull().sum()\n",
    "    columnas_con_nulos = nulos_por_columna[nulos_por_columna > 0]\n",
    "    \n",
    "    if not columnas_con_nulos.empty:\n",
    "        resultados['completitud']['valido'] = False\n",
    "        resultados['completitud']['detalles'] = columnas_con_nulos.to_dict()\n",
    "    \n",
    "    # 2. Consistencia: El total debe ser aproximadamente igual a precio * cantidad * (1 - descuento)\n",
    "    df_temp = df.copy()\n",
    "    df_temp['total_calculado'] = df_temp['precio'] * df_temp['cantidad'] * (1 - df_temp['descuento'])\n",
    "    df_temp['diferencia'] = abs(df_temp['total'] - df_temp['total_calculado'])\n",
    "    inconsistencias = df_temp[df_temp['diferencia'] > 0.01]\n",
    "    \n",
    "    if not inconsistencias.empty:\n",
    "        resultados['consistencia']['valido'] = False\n",
    "        resultados['consistencia']['detalles'] = {\n",
    "            'filas_inconsistentes': len(inconsistencias),\n",
    "            'ids': inconsistencias['id'].tolist()\n",
    "        }\n",
    "    \n",
    "    # 3. Validez: Los precios, cantidades y totales deben ser positivos\n",
    "    valores_negativos = {}\n",
    "    for columna in ['precio', 'cantidad', 'total']:\n",
    "        negativos = df[df[columna] < 0]\n",
    "        if not negativos.empty:\n",
    "            valores_negativos[columna] = len(negativos)\n",
    "    \n",
    "    # 4. Validez: Los descuentos deben estar entre 0 y 1\n",
    "    descuentos_invalidos = df[(df['descuento'] < 0) | (df['descuento'] > 1)]\n",
    "    if not descuentos_invalidos.empty:\n",
    "        valores_negativos['descuento'] = len(descuentos_invalidos)\n",
    "    \n",
    "    if valores_negativos:\n",
    "        resultados['validez']['valido'] = False\n",
    "        resultados['validez']['detalles'] = valores_negativos\n",
    "    \n",
    "    # Determina si el DataFrame es válido en general\n",
    "    resultados['valido'] = (\n",
    "        resultados['completitud']['valido'] and\n",
    "        resultados['consistencia']['valido'] and\n",
    "        resultados['validez']['valido']\n",
    "    )\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Tests\n",
    "def test_validar_df_valido(df_valido):\n",
    "    resultado = validar_calidad_datos(df_valido)\n",
    "    \n",
    "    # Verificamos que el DataFrame sea válido\n",
    "    assert resultado['valido'] is True\n",
    "    assert resultado['completitud']['valido'] is True\n",
    "    assert resultado['consistencia']['valido'] is True\n",
    "    assert resultado['validez']['valido'] is True\n",
    "\n",
    "def test_validar_df_con_nulos(df_con_nulos):\n",
    "    resultado = validar_calidad_datos(df_con_nulos)\n",
    "    \n",
    "    # Verificamos que se detecten los valores nulos\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['completitud']['valido'] is False\n",
    "    assert 'fecha' in resultado['completitud']['detalles']\n",
    "    assert 'categoria' in resultado['completitud']['detalles']\n",
    "\n",
    "def test_validar_df_inconsistente(df_inconsistente):\n",
    "    resultado = validar_calidad_datos(df_inconsistente)\n",
    "    \n",
    "    # Verificamos que se detecten las inconsistencias en los totales\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['consistencia']['valido'] is False\n",
    "    assert resultado['consistencia']['detalles']['filas_inconsistentes'] == 1\n",
    "    assert 2 in resultado['consistencia']['detalles']['ids']\n",
    "\n",
    "def test_validar_df_invalido(df_invalido):\n",
    "    resultado = validar_calidad_datos(df_invalido)\n",
    "    \n",
    "    # Verificamos que se detecten los valores inválidos\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['validez']['valido'] is False\n",
    "    assert 'precio' in resultado['validez']['detalles']\n",
    "    assert 'descuento' in resultado['validez']['detalles']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este notebook, has tenido la oportunidad de aplicar lo que has aprendido sobre pytest en el contexto de Data Engineering a través de una serie de ejercicios prácticos. Has implementado y testeado funciones para:\n",
    "\n",
    "1. Calcular la rentabilidad de productos\n",
    "2. Detectar anomalías en datos\n",
    "3. Segmentar productos según su precio y popularidad\n",
    "4. Crear un pipeline de preprocesamiento\n",
    "5. Validar la calidad de los datos\n",
    "\n",
    "Estos ejercicios te han permitido practicar diferentes aspectos del testing en Data Engineering, desde la validación de datos hasta el testing de pipelines completos. Al completar estos ejercicios, has desarrollado habilidades valiosas que podrás aplicar en tus propios proyectos de Data Engineering.\n",
    "\n",
    "Recuerda que el testing es una parte fundamental del desarrollo de software en general, y especialmente importante en Data Engineering, donde la calidad y confiabilidad de los datos son críticas. Implementar tests automatizados te ayudará a detectar problemas temprano, refactorizar con confianza y garantizar que tus pipelines de datos produzcan resultados correctos y consistentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
