{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso a Paso: Implementando Pytest en un Proyecto de Data Engineering\n",
    "\n",
    "En este notebook, vamos a seguir un proceso paso a paso para implementar pytest en un proyecto de Data Engineering. Veremos cómo configurar el entorno, escribir tests efectivos y ejecutarlos para verificar la calidad de nuestro código y datos.\n",
    "\n",
    "Utilizaremos nuestro dataset de ventas de productos y crearemos un pequeño proyecto que incluya funciones para procesar y validar estos datos. Luego, implementaremos tests para asegurar que estas funciones funcionen correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Configuración del Entorno\n",
    "\n",
    "Lo primero que necesitamos es asegurarnos de tener instaladas todas las bibliotecas necesarias. Para este tutorial, necesitaremos pytest, pytest-cov (para medir la cobertura de código), pandas y numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las bibliotecas necesarias\n",
    "!pip install pytest pytest-cov pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Estructura del Proyecto\n",
    "\n",
    "Para este tutorial, ya hemos creado una estructura de proyecto típica para Data Engineering:\n",
    "\n",
    "```\n",
    "pytest_tutorial/\n",
    "├── data/                  # Datos de ejemplo\n",
    "│   └── ventas_productos.csv\n",
    "├── notebooks/             # Jupyter notebooks para el tutorial\n",
    "├── utils/                 # Módulos de utilidades y funciones\n",
    "│   ├── __init__.py\n",
    "│   ├── data_processing.py # Funciones para procesar datos\n",
    "│   └── data_validation.py # Funciones para validar datos\n",
    "└── tests/                 # Tests de pytest\n",
    "    ├── __init__.py\n",
    "    ├── test_processing.py # Tests para funciones de procesamiento\n",
    "    └── test_validation.py # Tests para funciones de validación\n",
    "```\n",
    "\n",
    "Vamos a crear los directorios y archivos que faltan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los directorios y archivos necesarios\n",
    "# !mkdir -p ../tests\n",
    "# !touch ../utils/__init__.py\n",
    "# !touch ../tests/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Exploración del Dataset\n",
    "\n",
    "Antes de comenzar a escribir código y tests, vamos a explorar el dataset con el que trabajaremos. Esto nos ayudará a entender mejor los datos y a diseñar funciones y tests apropiados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "df = pd.read_csv('../data/ventas_productos.csv')\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información básica del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Creación de Funciones de Procesamiento de Datos\n",
    "\n",
    "Ahora vamos a crear algunas funciones para procesar nuestros datos de ventas. Estas funciones estarán en el módulo `utils.data_processing`.\n",
    "\n",
    "Primero, vamos a definir las funciones que queremos implementar:\n",
    "\n",
    "1. `calcular_metricas_ventas`: Calcula métricas básicas de ventas (total, promedio, etc.)\n",
    "2. `categorizar_productos_por_precio`: Categoriza productos según su precio\n",
    "3. `calcular_tendencia_ventas`: Calcula la tendencia de ventas por mes\n",
    "\n",
    "Vamos a implementar estas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../utils/data_processing.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calcular_metricas_ventas(df):\n",
    "    \"\"\"Calcula métricas de ventas a partir de un DataFrame de ventas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'precio', 'cantidad', 'descuento' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con métricas calculadas\n",
    "    \"\"\"\n",
    "    metricas = {\n",
    "        'total_ventas': df['total'].sum(),\n",
    "        'promedio_venta': df['total'].mean(),\n",
    "        'total_productos_vendidos': df['cantidad'].sum(),\n",
    "        'precio_promedio': df['precio'].mean(),\n",
    "        'descuento_promedio': df['descuento'].mean(),\n",
    "        'ahorro_total': (df['precio'] * df['cantidad'] * df['descuento']).sum()\n",
    "    }\n",
    "    return metricas\n",
    "\n",
    "def categorizar_productos_por_precio(df):\n",
    "    \"\"\"Categoriza productos según su precio.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columna 'precio'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame original con columna 'categoria_precio' añadida\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Evitamos modificar el DataFrame original\n",
    "    \n",
    "    # Definimos las categorías de precio\n",
    "    condiciones = [\n",
    "        (df['precio'] < 50),\n",
    "        (df['precio'] >= 50) & (df['precio'] < 100),\n",
    "        (df['precio'] >= 100) & (df['precio'] < 200),\n",
    "        (df['precio'] >= 200)\n",
    "    ]\n",
    "    categorias = ['Económico', 'Estándar', 'Premium', 'Lujo']\n",
    "    \n",
    "    # Creamos la nueva columna\n",
    "    df['categoria_precio'] = np.select(condiciones, categorias, default='Sin categoría')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calcular_tendencia_ventas(df):\n",
    "    \"\"\"Calcula la tendencia de ventas por mes.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'fecha' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con ventas totales por mes y variación porcentual\n",
    "    \"\"\"\n",
    "    # Convertimos la columna fecha a datetime\n",
    "    df = df.copy()\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    \n",
    "    # Extraemos el mes y agrupamos\n",
    "    df['mes'] = df['fecha'].dt.to_period('M')\n",
    "    ventas_mensuales = df.groupby('mes')['total'].sum().reset_index()\n",
    "    ventas_mensuales['mes'] = ventas_mensuales['mes'].astype(str)\n",
    "    \n",
    "    # Calculamos la variación porcentual\n",
    "    ventas_mensuales['variacion_porcentual'] = ventas_mensuales['total'].pct_change() * 100\n",
    "    \n",
    "    return ventas_mensuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Creación de Funciones de Validación de Datos\n",
    "\n",
    "Ahora vamos a crear algunas funciones para validar nuestros datos. Estas funciones estarán en el módulo `utils.data_validation`.\n",
    "\n",
    "Definiremos las siguientes funciones:\n",
    "\n",
    "1. `validar_completitud`: Verifica que no haya valores nulos en las columnas requeridas\n",
    "2. `validar_tipos_datos`: Verifica que las columnas tengan los tipos de datos esperados\n",
    "3. `validar_rango_valores`: Verifica que los valores estén dentro de los rangos especificados\n",
    "\n",
    "Vamos a implementar estas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../utils/data_validation.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def validar_completitud(df, columnas_requeridas=None):\n",
    "    \"\"\"Valida que no haya valores nulos en las columnas requeridas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        columnas_requeridas: Lista de columnas a verificar. Si es None, se verifican todas.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    if columnas_requeridas is None:\n",
    "        columnas_requeridas = df.columns.tolist()\n",
    "    \n",
    "    # Verificamos que todas las columnas requeridas existan\n",
    "    columnas_faltantes = [col for col in columnas_requeridas if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos valores nulos\n",
    "    nulos_por_columna = {col: int(df[col].isnull().sum()) for col in columnas_requeridas}\n",
    "    tiene_nulos = any(nulos_por_columna.values())\n",
    "    \n",
    "    if tiene_nulos:\n",
    "        columnas_con_nulos = [col for col, nulos in nulos_por_columna.items() if nulos > 0]\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Valores nulos encontrados en: {', '.join(columnas_con_nulos)}\",\n",
    "            'detalle': nulos_por_columna\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"No se encontraron valores nulos en las columnas requeridas\"\n",
    "    }\n",
    "\n",
    "def validar_tipos_datos(df, tipos_esperados):\n",
    "    \"\"\"Valida que las columnas tengan los tipos de datos esperados.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        tipos_esperados: Diccionario con columnas y sus tipos esperados\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    # Verificamos que todas las columnas existan\n",
    "    columnas_faltantes = [col for col in tipos_esperados.keys() if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos los tipos de datos\n",
    "    tipos_incorrectos = {}\n",
    "    for columna, tipo_esperado in tipos_esperados.items():\n",
    "        tipo_actual = df[columna].dtype\n",
    "        if not pd.api.types.is_dtype_equal(tipo_actual, tipo_esperado):\n",
    "            # Para tipos numéricos, verificamos si podemos convertir sin pérdida de información\n",
    "            if pd.api.types.is_numeric_dtype(tipo_esperado) and pd.api.types.is_numeric_dtype(tipo_actual):\n",
    "                continue\n",
    "            \n",
    "            # Para fechas, verificamos si podemos convertir\n",
    "            if tipo_esperado == 'datetime64[ns]' and pd.api.types.is_string_dtype(tipo_actual):\n",
    "                try:\n",
    "                    pd.to_datetime(df[columna])\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            tipos_incorrectos[columna] = {'esperado': tipo_esperado, 'actual': str(tipo_actual)}\n",
    "    \n",
    "    if tipos_incorrectos:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Tipos de datos incorrectos en {len(tipos_incorrectos)} columnas\",\n",
    "            'detalle': tipos_incorrectos\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"Todos los tipos de datos son correctos\"\n",
    "    }\n",
    "\n",
    "def validar_rango_valores(df, rangos):\n",
    "    \"\"\"Valida que los valores estén dentro de los rangos especificados.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        rangos: Diccionario con columnas y sus rangos (min, max)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    # Verificamos que todas las columnas existan\n",
    "    columnas_faltantes = [col for col in rangos.keys() if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos los rangos\n",
    "    fuera_de_rango = {}\n",
    "    for columna, (min_val, max_val) in rangos.items():\n",
    "        # Verificamos mínimo\n",
    "        if min_val is not None:\n",
    "            valores_bajo_minimo = df[df[columna] < min_val]\n",
    "            if not valores_bajo_minimo.empty:\n",
    "                if columna not in fuera_de_rango:\n",
    "                    fuera_de_rango[columna] = {}\n",
    "                fuera_de_rango[columna]['bajo_minimo'] = {\n",
    "                    'cantidad': len(valores_bajo_minimo),\n",
    "                    'minimo_esperado': min_val,\n",
    "                    'valor_minimo_encontrado': float(valores_bajo_minimo[columna].min())\n",
    "                }\n",
    "        \n",
    "        # Verificamos máximo\n",
    "        if max_val is not None:\n",
    "            valores_sobre_maximo = df[df[columna] > max_val]\n",
    "            if not valores_sobre_maximo.empty:\n",
    "                if columna not in fuera_de_rango:\n",
    "                    fuera_de_rango[columna] = {}\n",
    "                fuera_de_rango[columna]['sobre_maximo'] = {\n",
    "                    'cantidad': len(valores_sobre_maximo),\n",
    "                    'maximo_esperado': max_val,\n",
    "                    'valor_maximo_encontrado': float(valores_sobre_maximo[columna].max())\n",
    "                }\n",
    "    \n",
    "    if fuera_de_rango:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Valores fuera de rango en {len(fuera_de_rango)} columnas\",\n",
    "            'detalle': fuera_de_rango\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"Todos los valores están dentro de los rangos especificados\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Creación de Tests para Funciones de Procesamiento\n",
    "\n",
    "Ahora que tenemos nuestras funciones de procesamiento, vamos a crear tests para verificar que funcionan correctamente. Estos tests estarán en el archivo `tests/test_processing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../tests/test_processing.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from utils.data_processing import calcular_metricas_ventas, categorizar_productos_por_precio, calcular_tendencia_ventas\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas_sample():\n",
    "    \"\"\"Fixture que crea un pequeño DataFrame de muestra para testing.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas_completo():\n",
    "    \"\"\"Fixture que carga el dataset completo de ventas.\"\"\"\n",
    "    return pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'ventas_productos.csv'))\n",
    "\n",
    "def test_calcular_metricas_ventas(df_ventas_sample):\n",
    "    \"\"\"Test para la función de cálculo de métricas de ventas.\"\"\"\n",
    "    metricas = calcular_metricas_ventas(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que todas las métricas esperadas estén presentes\n",
    "    assert set(metricas.keys()) == {'total_ventas', 'promedio_venta', 'total_productos_vendidos', \n",
    "                                    'precio_promedio', 'descuento_promedio', 'ahorro_total'}\n",
    "    \n",
    "    # Verificamos algunos cálculos específicos\n",
    "    assert metricas['total_ventas'] == pytest.approx(1516.94, 0.01)\n",
    "    assert metricas['total_productos_vendidos'] == 6\n",
    "    assert metricas['precio_promedio'] == pytest.approx(403.32, 0.01)\n",
    "\n",
    "def test_calcular_metricas_ventas_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para la función de cálculo de métricas con el dataset completo.\"\"\"\n",
    "    metricas = calcular_metricas_ventas(df_ventas_completo)\n",
    "    \n",
    "    # Verificamos que todas las métricas sean números válidos\n",
    "    for metrica, valor in metricas.items():\n",
    "        assert isinstance(valor, (int, float))\n",
    "        assert not np.isnan(valor)\n",
    "        assert not np.isinf(valor)\n",
    "\n",
    "def test_categorizar_productos_por_precio(df_ventas_sample):\n",
    "    \"\"\"Test para la función de categorización de productos por precio.\"\"\"\n",
    "    df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que se haya añadido la columna de categoría de precio\n",
    "    assert 'categoria_precio' in df_categorizado.columns\n",
    "    \n",
    "    # Verificamos que las categorías sean correctas\n",
    "    assert df_categorizado.loc[0, 'categoria_precio'] == 'Lujo'  # Laptop HP: 899.99\n",
    "    assert df_categorizado.loc[1, 'categoria_precio'] == 'Premium'  # Monitor Dell: 249.99\n",
    "    assert df_categorizado.loc[2, 'categoria_precio'] == 'Estándar'  # Teclado Logitech: 59.99\n",
    "    \n",
    "    # Verificamos que el DataFrame original no se haya modificado\n",
    "    assert 'categoria_precio' not in df_ventas_sample.columns\n",
    "\n",
    "def test_categorizar_productos_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para la función de categorización con el dataset completo.\"\"\"\n",
    "    df_categorizado = categorizar_productos_por_precio(df_ventas_completo)\n",
    "    \n",
    "    # Verificamos que se haya añadido la columna de categoría de precio\n",
    "    assert 'categoria_precio' in df_categorizado.columns\n",
    "    \n",
    "    # Verificamos que todas las filas tengan una categoría válida\n",
    "    categorias_validas = {'Económico', 'Estándar', 'Premium', 'Lujo', 'Sin categoría'}\n",
    "    assert set(df_categorizado['categoria_precio'].unique()).issubset(categorias_validas)\n",
    "    \n",
    "    # Verificamos que haya al menos un producto en cada categoría principal\n",
    "    for categoria in ['Económico', 'Estándar', 'Premium', 'Lujo']:\n",
    "        assert categoria in df_categorizado['categoria_precio'].values, f\"No hay productos en la categoría {categoria}\"\n",
    "\n",
    "def test_calcular_tendencia_ventas(df_ventas_sample):\n",
    "    \"\"\"Test para la función de cálculo de tendencia de ventas.\"\"\"\n",
    "    tendencia = calcular_tendencia_ventas(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que el DataFrame tenga las columnas esperadas\n",
    "    assert set(tendencia.columns) == {'mes', 'total', 'variacion_porcentual'}\n",
    "    \n",
    "    # Verificamos que solo haya un mes (ya que todas las fechas son de enero 2023)\n",
    "    assert len(tendencia) == 1\n",
    "    assert tendencia.iloc[0]['mes'] == '2023-01'\n",
    "    assert tendencia.iloc[0]['total'] == pytest.approx(1516.94, 0.01)\n",
    "    assert np.isnan(tendencia.iloc[0]['variacion_porcentual'])  # No hay mes anterior para comparar\n",
    "\n",
    "def test_calcular_tendencia_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para la función de tendencia con el dataset completo.\"\"\"\n",
    "    tendencia = calcular_tendencia_ventas(df_ventas_completo)\n",
    "    \n",
    "    # Verificamos que el DataFrame tenga las columnas esperadas\n",
    "    assert set(tendencia.columns) == {'mes', 'total', 'variacion_porcentual'}\n",
    "    \n",
    "    # Verificamos que haya al menos un mes\n",
    "    assert len(tendencia) > 0\n",
    "    \n",
    "    # Verificamos que los meses estén en formato YYYY-MM\n",
    "    import re\n",
    "    for mes in tendencia['mes']:\n",
    "        assert re.match(r'^\\d{4}-\\d{2}$', mes), f\"El mes {mes} no tiene el formato esperado (YYYY-MM)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Creación de Tests para Funciones de Validación\n",
    "\n",
    "Ahora vamos a crear tests para nuestras funciones de validación de datos. Estos tests estarán en el archivo `tests/test_validation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../tests/test_validation.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from utils.data_validation import validar_completitud, validar_tipos_datos, validar_rango_valores\n",
    "\n",
    "@pytest.fixture\n",
    "def df_valido():\n",
    "    \"\"\"Fixture que crea un DataFrame válido para testing.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_con_nulos():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores nulos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', None, '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', None],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, None],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_tipos_incorrectos():\n",
    "    \"\"\"Fixture que crea un DataFrame con tipos de datos incorrectos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': ['899.99', '249.99', '59.99'],  # Strings en lugar de float\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_fuera_de_rango():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores fuera de rango.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, -3],  # Valor negativo\n",
    "        'descuento': [0.05, 0.00, 1.5],  # Descuento mayor a 1 (100%)\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas_completo():\n",
    "    \"\"\"Fixture que carga el dataset completo de ventas.\"\"\"\n",
    "    return pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'ventas_productos.csv'))\n",
    "\n",
    "def test_validar_completitud_sin_nulos(df_valido):\n",
    "    \"\"\"Test para validar completitud en un DataFrame sin valores nulos.\"\"\"\n",
    "    resultado = validar_completitud(df_valido)\n",
    "    assert resultado['valido'] is True\n",
    "    assert 'mensaje' in resultado\n",
    "\n",
    "def test_validar_completitud_con_nulos(df_con_nulos):\n",
    "    \"\"\"Test para validar completitud en un DataFrame con valores nulos.\"\"\"\n",
    "    resultado = validar_completitud(df_con_nulos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'error' in resultado\n",
    "    assert 'detalle' in resultado\n",
    "    assert resultado['detalle']['fecha'] == 1\n",
    "    assert resultado['detalle']['categoria'] == 1\n",
    "    assert resultado['detalle']['cantidad'] == 1\n",
    "\n",
    "def test_validar_completitud_columnas_especificas(df_con_nulos):\n",
    "    \"\"\"Test para validar completitud solo en columnas específicas.\"\"\"\n",
    "    # Validamos solo columnas que no tienen nulos\n",
    "    resultado = validar_completitud(df_con_nulos, ['id', 'producto', 'precio', 'descuento', 'total'])\n",
    "    assert resultado['valido'] is True\n",
    "    \n",
    "    # Validamos una columna que tiene nulos\n",
    "    resultado = validar_completitud(df_con_nulos, ['id', 'fecha'])\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['detalle']['fecha'] == 1\n",
    "\n",
    "def test_validar_completitud_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para validar completitud en el dataset completo.\"\"\"\n",
    "    resultado = validar_completitud(df_ventas_completo)\n",
    "    assert resultado['valido'] is True, \"El dataset completo no debería tener valores nulos\"\n",
    "\n",
    "def test_validar_tipos_datos_correctos(df_valido):\n",
    "    \"\"\"Test para validar tipos de datos correctos.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'precio': 'float64',\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_valido, tipos_esperados)\n",
    "    assert resultado['valido'] is True\n",
    "\n",
    "def test_validar_tipos_datos_incorrectos(df_tipos_incorrectos):\n",
    "    \"\"\"Test para validar tipos de datos incorrectos.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'precio': 'float64',  # En df_tipos_incorrectos, precio es string\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_tipos_incorrectos, tipos_esperados)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'precio' in resultado['detalle']\n",
    "\n",
    "def test_validar_tipos_datos_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para validar tipos de datos en el dataset completo.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'fecha': 'object',  # Las fechas se cargan como strings (object)\n",
    "        'producto': 'object',\n",
    "        'categoria': 'object',\n",
    "        'precio': 'float64',\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_ventas_completo, tipos_esperados)\n",
    "    assert resultado['valido'] is True, \"Los tipos de datos en el dataset completo deberían ser correctos\"\n",
    "\n",
    "def test_validar_rango_valores_dentro_de_rango(df_valido):\n",
    "    \"\"\"Test para validar rangos de valores dentro de los límites.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),\n",
    "        'descuento': (0, 1),\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_valido, rangos)\n",
    "    assert resultado['valido'] is True\n",
    "\n",
    "def test_validar_rango_valores_fuera_de_rango(df_fuera_de_rango):\n",
    "    \"\"\"Test para validar rangos de valores fuera de los límites.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),  # En df_fuera_de_rango, hay un valor negativo\n",
    "        'descuento': (0, 1),  # En df_fuera_de_rango, hay un descuento > 1\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_fuera_de_rango, rangos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'cantidad' in resultado['detalle']\n",
    "    assert 'descuento' in resultado['detalle']\n",
    "    assert 'bajo_minimo' in resultado['detalle']['cantidad']\n",
    "    assert 'sobre_maximo' in resultado['detalle']['descuento']\n",
    "\n",
    "def test_validar_rango_valores_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para validar rangos de valores en el dataset completo.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),\n",
    "        'descuento': (0, 1),\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_ventas_completo, rangos)\n",
    "    assert resultado['valido'] is True, \"Todos los valores en el dataset completo deberían estar dentro de los rangos especificados\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Ejecución de Tests\n",
    "\n",
    "Ahora que tenemos nuestras funciones y tests, vamos a ejecutar los tests para verificar que todo funciona correctamente.\n",
    "\n",
    "Primero, vamos a ejecutar los tests de procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python -m pytest tests/test_processing.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a ejecutar los tests de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python -m pytest tests/test_validation.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ejecutar todos los tests a la vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python -m pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 9: Medición de Cobertura de Código\n",
    "\n",
    "Una métrica importante en testing es la cobertura de código, que mide qué porcentaje de nuestro código está siendo ejecutado por los tests. Vamos a medir la cobertura de nuestros tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python -m pytest --cov=utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener un informe más detallado de la cobertura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python -m pytest --cov=utils --cov-report=term-missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 10: Uso de Marcadores para Categorizar Tests\n",
    "\n",
    "Los marcadores nos permiten categorizar los tests y seleccionar subconjuntos específicos para ejecutar. Vamos a crear un nuevo archivo de tests con marcadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../tests/test_with_markers.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas():\n",
    "    \"\"\"Fixture que carga el dataset de ventas.\"\"\"\n",
    "    return pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'ventas_productos.csv'))\n",
    "\n",
    "@pytest.mark.rapido\n",
    "def test_columnas_requeridas(df_ventas):\n",
    "    \"\"\"Test rápido que verifica que el DataFrame tenga las columnas requeridas.\"\"\"\n",
    "    columnas_requeridas = ['id', 'fecha', 'producto', 'categoria', 'precio', 'cantidad', 'descuento', 'total']\n",
    "    for columna in columnas_requeridas:\n",
    "        assert columna in df_ventas.columns, f\"La columna {columna} debería estar presente\"\n",
    "\n",
    "@pytest.mark.lento\n",
    "def test_calculo_intensivo(df_ventas):\n",
    "    \"\"\"Test lento que simula un cálculo intensivo.\"\"\"\n",
    "    # Simulamos un cálculo que toma tiempo\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Realizamos algún cálculo con el DataFrame\n",
    "    resultado = df_ventas.groupby(['categoria', 'fecha']).agg({'total': 'sum'}).reset_index()\n",
    "    assert not resultado.empty, \"El resultado no debería estar vacío\"\n",
    "\n",
    "@pytest.mark.validacion\n",
    "def test_valores_no_negativos(df_ventas):\n",
    "    \"\"\"Test que verifica que no haya valores negativos en columnas numéricas.\"\"\"\n",
    "    columnas_numericas = ['precio', 'cantidad', 'total']\n",
    "    for columna in columnas_numericas:\n",
    "        assert (df_ventas[columna] >= 0).all(), f\"No debería haber valores negativos en {columna}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar solo los tests rápidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python -m pytest tests/test_with_markers.py -m rapido -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar solo los tests de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python -m pytest tests/test_with_markers.py -m validacion -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 11: Configuración de Pytest\n",
    "\n",
    "Podemos configurar pytest para personalizar su comportamiento. Esto se hace típicamente a través de un archivo `pytest.ini` o `conftest.py`. Vamos a crear un archivo `pytest.ini` básico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../pytest.ini\n",
    "[pytest]\n",
    "markers =\n",
    "    rapido: tests que se ejecutan rápidamente\n",
    "    lento: tests que toman más tiempo en ejecutarse\n",
    "    validacion: tests que validan la calidad de los datos\n",
    "\n",
    "testpaths = tests\n",
    "python_files = test_*.py\n",
    "python_classes = Test*\n",
    "python_functions = test_*\n",
    "\n",
    "# Opciones de verbosidad y formato de salida\n",
    "addopts = -v --no-header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 12: Creación de un Script para Ejecutar Tests\n",
    "\n",
    "Para facilitar la ejecución de tests, podemos crear un script que ejecute los tests y genere un informe de cobertura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../run_tests.py\n",
    "#!/usr/bin/env python\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Ejecuta los tests y genera un informe de cobertura.\"\"\"\n",
    "    print(\"Ejecutando tests...\")\n",
    "    result = subprocess.run([\"pytest\", \"--cov=utils\", \"--cov-report=term-missing\"], capture_output=True, text=True)\n",
    "    \n",
    "    print(\"\\nResultados de los tests:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"\\nErrores:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    return result.returncode\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cambiamos al directorio raíz del proyecto\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "    \n",
    "    # Ejecutamos los tests\n",
    "    exit_code = run_tests()\n",
    "    \n",
    "    # Salimos con el código de retorno de pytest\n",
    "    sys.exit(exit_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el script ejecutable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ../run_tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y lo ejecutamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python run_tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este notebook, hemos seguido un proceso paso a paso para implementar pytest en un proyecto de Data Engineering. Hemos visto cómo:\n",
    "\n",
    "1. Configurar el entorno y la estructura del proyecto\n",
    "2. Explorar el dataset para entender los datos\n",
    "3. Crear funciones de procesamiento y validación de datos\n",
    "4. Escribir tests para verificar estas funciones\n",
    "5. Ejecutar los tests y medir la cobertura de código\n",
    "6. Usar marcadores para categorizar y seleccionar tests\n",
    "7. Configurar pytest para personalizar su comportamiento\n",
    "8. Crear un script para facilitar la ejecución de tests\n",
    "\n",
    "Este enfoque sistemático nos permite asegurar la calidad de nuestro código y datos, lo que es fundamental en proyectos de Data Engineering donde la precisión y confiabilidad son críticas.\n",
    "\n",
    "En el siguiente notebook, veremos ejemplos más avanzados de pytest aplicados a escenarios específicos de Data Engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
