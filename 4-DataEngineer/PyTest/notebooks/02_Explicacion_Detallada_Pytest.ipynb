{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicación Detallada de Pytest para Data Engineers\n",
    "\n",
    "En este notebook, profundizaremos en los conceptos fundamentales de pytest y cómo aplicarlos específicamente en proyectos de Data Engineering. Exploraremos la sintaxis, características y patrones comunes que hacen de pytest una herramienta tan poderosa para el testing de código relacionado con datos.\n",
    "\n",
    "## Fundamentos de Pytest\n",
    "\n",
    "Pytest simplifica enormemente la escritura de tests en Python. A diferencia de frameworks como unittest, que requiere la creación de clases que hereden de `TestCase`, pytest permite escribir tests como simples funciones. Esta simplicidad hace que sea más fácil comenzar a escribir tests y mantenerlos a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de Pytest\n",
    "\n",
    "Si aún no has instalado pytest, puedes hacerlo fácilmente con pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytest pytest-cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estructura básica de un test en Pytest\n",
    "\n",
    "En pytest, un test es simplemente una función cuyo nombre comienza con `test_`. Dentro de esta función, utilizamos aserciones (`assert`) para verificar que el comportamiento del código es el esperado.\n",
    "\n",
    "Veamos un ejemplo simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de una función simple que queremos testear\n",
    "def calcular_total_con_impuesto(monto, tasa_impuesto=0.16):\n",
    "    \"\"\"Calcula el monto total incluyendo impuestos.\"\"\"\n",
    "    return monto * (1 + tasa_impuesto)\n",
    "\n",
    "# Test para la función\n",
    "def test_calcular_total_con_impuesto():\n",
    "    # Caso 1: Impuesto por defecto (16%)\n",
    "    assert calcular_total_con_impuesto(100) == 116.0\n",
    "    \n",
    "    # Caso 2: Impuesto personalizado (10%)\n",
    "    assert calcular_total_con_impuesto(100, 0.10) == 110.0\n",
    "    \n",
    "    # Caso 3: Monto cero\n",
    "    assert calcular_total_con_impuesto(0) == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutando tests\n",
    "\n",
    "Normalmente, ejecutaríamos los tests desde la línea de comandos con el comando `pytest`. Sin embargo, en un notebook podemos usar el módulo `pytest` directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la función y el test en un archivo temporal para ejecutarlo\n",
    "%%file ../tests/temp_test.py\n",
    "def calcular_total_con_impuesto(monto, tasa_impuesto=0.16):\n",
    "    \"\"\"Calcula el monto total incluyendo impuestos.\"\"\"\n",
    "    return monto * (1 + tasa_impuesto)\n",
    "\n",
    "def test_calcular_total_con_impuesto():\n",
    "    # Caso 1: Impuesto por defecto (16%)\n",
    "    assert calcular_total_con_impuesto(100) == 116.0\n",
    "    \n",
    "    # Caso 2: Impuesto personalizado (10%)\n",
    "    assert calcular_total_con_impuesto(100, 0.10) == 110.0\n",
    "    \n",
    "    # Caso 3: Monto cero\n",
    "    assert calcular_total_con_impuesto(0) == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos pytest en el archivo temporal\n",
    "!pytest -xvs temp_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características Avanzadas de Pytest\n",
    "\n",
    "Pytest ofrece muchas características avanzadas que lo hacen especialmente útil para testing en Data Engineering. Veamos algunas de las más importantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fixtures: Preparación y limpieza del entorno de pruebas\n",
    "\n",
    "Las fixtures son funciones que pytest ejecuta antes (y opcionalmente después) de los tests para preparar el entorno de pruebas. Son extremadamente útiles en Data Engineering para cargar datasets, configurar conexiones a bases de datos, o preparar cualquier otro recurso necesario para los tests.\n",
    "\n",
    "Veamos un ejemplo de cómo usar fixtures para cargar nuestro dataset de ventas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_with_fixtures.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas():\n",
    "    \"\"\"Fixture que carga el dataset de ventas.\"\"\"\n",
    "    return pd.read_csv('../data/ventas_productos.csv')\n",
    "\n",
    "def calcular_ingresos_por_categoria(df):\n",
    "    \"\"\"Calcula los ingresos totales por categoría de producto.\"\"\"\n",
    "    return df.groupby('categoria')['total'].sum().to_dict()\n",
    "\n",
    "def test_calcular_ingresos_por_categoria(df_ventas):\n",
    "    \"\"\"Test que verifica el cálculo de ingresos por categoría.\"\"\"\n",
    "    # Calculamos los ingresos por categoría\n",
    "    ingresos = calcular_ingresos_por_categoria(df_ventas)\n",
    "    \n",
    "    # Verificamos que todas las categorías esperadas estén presentes\n",
    "    assert set(ingresos.keys()) == {'Electrónica', 'Accesorios', 'Almacenamiento', 'Componentes', 'Audio', 'Redes', 'Wearables'}\n",
    "    \n",
    "    # Verificamos que los ingresos sean números positivos\n",
    "    for categoria, ingreso in ingresos.items():\n",
    "        assert ingreso > 0, f\"Los ingresos para {categoria} deberían ser positivos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos el test con fixtures\n",
    "!pytest -xvs test_with_fixtures.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parametrización: Ejecutar el mismo test con diferentes datos\n",
    "\n",
    "La parametrización es una característica poderosa que permite ejecutar el mismo test con diferentes conjuntos de datos de entrada. Esto es especialmente útil en Data Engineering, donde a menudo necesitamos verificar que nuestras funciones manejen correctamente diferentes tipos de datos o escenarios.\n",
    "\n",
    "Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_parametrized.py\n",
    "import pytest\n",
    "\n",
    "def validar_formato_fecha(fecha):\n",
    "    \"\"\"Valida que una fecha tenga el formato YYYY-MM-DD.\"\"\"\n",
    "    import re\n",
    "    pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "    return bool(re.match(pattern, fecha))\n",
    "\n",
    "@pytest.mark.parametrize(\"fecha,esperado\", [\n",
    "    (\"2023-01-05\", True),   # Formato correcto\n",
    "    (\"2023-1-5\", False),    # Día y mes sin ceros iniciales\n",
    "    (\"01-05-2023\", False),  # Formato incorrecto (DD-MM-YYYY)\n",
    "    (\"2023/01/05\", False),  # Separadores incorrectos\n",
    "    (\"20230105\", False),    # Sin separadores\n",
    "    (\"2023-01-32\", True),   # Día inválido pero formato correcto\n",
    "    (\"\", False),            # Cadena vacía\n",
    "])\n",
    "def test_validar_formato_fecha(fecha, esperado):\n",
    "    \"\"\"Test parametrizado para la función de validación de fechas.\"\"\"\n",
    "    assert validar_formato_fecha(fecha) == esperado, f\"La validación de '{fecha}' debería ser {esperado}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos el test parametrizado\n",
    "!pytest -xvs test_parametrized.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Marcadores: Categorizar y seleccionar tests\n",
    "\n",
    "Los marcadores permiten categorizar los tests y seleccionar subconjuntos específicos para ejecutar. Esto es útil cuando tenemos diferentes tipos de tests (unitarios, integración, etc.) o cuando algunos tests son lentos o requieren recursos especiales.\n",
    "\n",
    "Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_with_markers.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas():\n",
    "    return pd.read_csv('../data/ventas_productos.csv')\n",
    "\n",
    "@pytest.mark.rapido\n",
    "def test_columnas_requeridas(df_ventas):\n",
    "    \"\"\"Test rápido que verifica que el DataFrame tenga las columnas requeridas.\"\"\"\n",
    "    columnas_requeridas = ['id', 'fecha', 'producto', 'categoria', 'precio', 'cantidad', 'descuento', 'total']\n",
    "    for columna in columnas_requeridas:\n",
    "        assert columna in df_ventas.columns, f\"La columna {columna} debería estar presente\"\n",
    "\n",
    "@pytest.mark.lento\n",
    "def test_calculo_intensivo(df_ventas):\n",
    "    \"\"\"Test lento que simula un cálculo intensivo.\"\"\"\n",
    "    # Simulamos un cálculo que toma tiempo\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Realizamos algún cálculo con el DataFrame\n",
    "    resultado = df_ventas.groupby(['categoria', 'fecha']).agg({'total': 'sum'}).reset_index()\n",
    "    assert not resultado.empty, \"El resultado no debería estar vacío\"\n",
    "\n",
    "@pytest.mark.validacion\n",
    "def test_valores_no_negativos(df_ventas):\n",
    "    \"\"\"Test que verifica que no haya valores negativos en columnas numéricas.\"\"\"\n",
    "    columnas_numericas = ['precio', 'cantidad', 'total']\n",
    "    for columna in columnas_numericas:\n",
    "        assert (df_ventas[columna] >= 0).all(), f\"No debería haber valores negativos en {columna}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos solo los tests rápidos\n",
    "!pytest -xvs test_with_markers.py -m rapido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fixtures con alcance (scope)\n",
    "\n",
    "Las fixtures pueden tener diferentes alcances (function, class, module, session) para controlar cuándo se crean y destruyen. Esto es útil para optimizar recursos, especialmente cuando trabajamos con grandes conjuntos de datos o conexiones a bases de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_fixture_scope.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Esta fixture se ejecutará una vez por sesión de pytest\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def df_ventas_session():\n",
    "    print(\"\\nCargando dataset (scope=session)...\")\n",
    "    time.sleep(1)  # Simulamos una carga lenta\n",
    "    df = pd.read_csv('../data/ventas_productos.csv')\n",
    "    print(\"Dataset cargado (scope=session)\")\n",
    "    return df\n",
    "\n",
    "# Esta fixture se ejecutará una vez por función de test\n",
    "@pytest.fixture(scope=\"function\")\n",
    "def df_ventas_function():\n",
    "    print(\"\\nCargando dataset (scope=function)...\")\n",
    "    time.sleep(0.5)  # Simulamos una carga lenta\n",
    "    df = pd.read_csv('../data/ventas_productos.csv')\n",
    "    print(\"Dataset cargado (scope=function)\")\n",
    "    return df\n",
    "\n",
    "def test_1_con_session_fixture(df_ventas_session):\n",
    "    print(\"Ejecutando test_1_con_session_fixture\")\n",
    "    assert len(df_ventas_session) > 0\n",
    "\n",
    "def test_2_con_session_fixture(df_ventas_session):\n",
    "    print(\"Ejecutando test_2_con_session_fixture\")\n",
    "    assert 'total' in df_ventas_session.columns\n",
    "\n",
    "def test_1_con_function_fixture(df_ventas_function):\n",
    "    print(\"Ejecutando test_1_con_function_fixture\")\n",
    "    assert len(df_ventas_function) > 0\n",
    "\n",
    "def test_2_con_function_fixture(df_ventas_function):\n",
    "    print(\"Ejecutando test_2_con_function_fixture\")\n",
    "    assert 'total' in df_ventas_function.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos los tests con fixtures de diferentes alcances\n",
    "!pytest -xvs test_fixture_scope.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones Específicas para Data Engineering\n",
    "\n",
    "Ahora que hemos visto las características fundamentales de pytest, veamos cómo aplicarlas específicamente en escenarios comunes de Data Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Testing de funciones de transformación de datos\n",
    "\n",
    "En Data Engineering, a menudo escribimos funciones para transformar datos. Pytest nos permite verificar que estas transformaciones produzcan los resultados esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../utils/data_processing.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calcular_metricas_ventas(df):\n",
    "    \"\"\"Calcula métricas de ventas a partir de un DataFrame de ventas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'precio', 'cantidad', 'descuento' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con métricas calculadas\n",
    "    \"\"\"\n",
    "    metricas = {\n",
    "        'total_ventas': df['total'].sum(),\n",
    "        'promedio_venta': df['total'].mean(),\n",
    "        'total_productos_vendidos': df['cantidad'].sum(),\n",
    "        'precio_promedio': df['precio'].mean(),\n",
    "        'descuento_promedio': df['descuento'].mean(),\n",
    "        'ahorro_total': (df['precio'] * df['cantidad'] * df['descuento']).sum()\n",
    "    }\n",
    "    return metricas\n",
    "\n",
    "def categorizar_productos_por_precio(df):\n",
    "    \"\"\"Categoriza productos según su precio.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columna 'precio'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame original con columna 'categoria_precio' añadida\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Evitamos modificar el DataFrame original\n",
    "    \n",
    "    # Definimos las categorías de precio\n",
    "    condiciones = [\n",
    "        (df['precio'] < 50),\n",
    "        (df['precio'] >= 50) & (df['precio'] < 100),\n",
    "        (df['precio'] >= 100) & (df['precio'] < 200),\n",
    "        (df['precio'] >= 200)\n",
    "    ]\n",
    "    categorias = ['Económico', 'Estándar', 'Premium', 'Lujo']\n",
    "    \n",
    "    # Creamos la nueva columna\n",
    "    df['categoria_precio'] = np.select(condiciones, categorias, default='Sin categoría')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calcular_tendencia_ventas(df):\n",
    "    \"\"\"Calcula la tendencia de ventas por mes.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'fecha' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con ventas totales por mes y variación porcentual\n",
    "    \"\"\"\n",
    "    # Convertimos la columna fecha a datetime\n",
    "    df = df.copy()\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    \n",
    "    # Extraemos el mes y agrupamos\n",
    "    df['mes'] = df['fecha'].dt.to_period('M')\n",
    "    ventas_mensuales = df.groupby('mes')['total'].sum().reset_index()\n",
    "    ventas_mensuales['mes'] = ventas_mensuales['mes'].astype(str)\n",
    "    \n",
    "    # Calculamos la variación porcentual\n",
    "    ventas_mensuales['variacion_porcentual'] = ventas_mensuales['total'].pct_change() * 100\n",
    "    \n",
    "    return ventas_mensuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_data_processing.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_processing import calcular_metricas_ventas, categorizar_productos_por_precio, calcular_tendencia_ventas\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas_sample():\n",
    "    \"\"\"Fixture que crea un pequeño DataFrame de muestra para testing.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_calcular_metricas_ventas(df_ventas_sample):\n",
    "    \"\"\"Test para la función de cálculo de métricas de ventas.\"\"\"\n",
    "    metricas = calcular_metricas_ventas(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que todas las métricas esperadas estén presentes\n",
    "    assert set(metricas.keys()) == {'total_ventas', 'promedio_venta', 'total_productos_vendidos', \n",
    "                                    'precio_promedio', 'descuento_promedio', 'ahorro_total'}\n",
    "    \n",
    "    # Verificamos algunos cálculos específicos\n",
    "    assert metricas['total_ventas'] == pytest.approx(1516.94, 0.01)\n",
    "    assert metricas['total_productos_vendidos'] == 6\n",
    "    assert metricas['precio_promedio'] == pytest.approx(403.32, 0.01)\n",
    "\n",
    "def test_categorizar_productos_por_precio(df_ventas_sample):\n",
    "    \"\"\"Test para la función de categorización de productos por precio.\"\"\"\n",
    "    df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que se haya añadido la columna de categoría de precio\n",
    "    assert 'categoria_precio' in df_categorizado.columns\n",
    "    \n",
    "    # Verificamos que las categorías sean correctas\n",
    "    assert df_categorizado.loc[0, 'categoria_precio'] == 'Lujo'  # Laptop HP: 899.99\n",
    "    assert df_categorizado.loc[1, 'categoria_precio'] == 'Premium'  # Monitor Dell: 249.99\n",
    "    assert df_categorizado.loc[2, 'categoria_precio'] == 'Estándar'  # Teclado Logitech: 59.99\n",
    "    \n",
    "    # Verificamos que el DataFrame original no se haya modificado\n",
    "    assert 'categoria_precio' not in df_ventas_sample.columns\n",
    "\n",
    "def test_calcular_tendencia_ventas(df_ventas_sample):\n",
    "    \"\"\"Test para la función de cálculo de tendencia de ventas.\"\"\"\n",
    "    tendencia = calcular_tendencia_ventas(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que el DataFrame tenga las columnas esperadas\n",
    "    assert set(tendencia.columns) == {'mes', 'total', 'variacion_porcentual'}\n",
    "    \n",
    "    # Verificamos que solo haya un mes (ya que todas las fechas son de enero 2023)\n",
    "    assert len(tendencia) == 1\n",
    "    assert tendencia.iloc[0]['mes'] == '2023-01'\n",
    "    assert tendencia.iloc[0]['total'] == pytest.approx(1516.94, 0.01)\n",
    "    assert np.isnan(tendencia.iloc[0]['variacion_porcentual'])  # No hay mes anterior para comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos los tests de procesamiento de datos\n",
    "!pytest -xvs test_data_processing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing de validación de datos\n",
    "\n",
    "Otra aplicación común en Data Engineering es la validación de datos. Pytest nos permite verificar que nuestras funciones de validación detecten correctamente problemas en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../utils/data_validation.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def validar_completitud(df, columnas_requeridas=None):\n",
    "    \"\"\"Valida que no haya valores nulos en las columnas requeridas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        columnas_requeridas: Lista de columnas a verificar. Si es None, se verifican todas.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    if columnas_requeridas is None:\n",
    "        columnas_requeridas = df.columns.tolist()\n",
    "    \n",
    "    # Verificamos que todas las columnas requeridas existan\n",
    "    columnas_faltantes = [col for col in columnas_requeridas if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos valores nulos\n",
    "    nulos_por_columna = {col: int(df[col].isnull().sum()) for col in columnas_requeridas}\n",
    "    tiene_nulos = any(nulos_por_columna.values())\n",
    "    \n",
    "    if tiene_nulos:\n",
    "        columnas_con_nulos = [col for col, nulos in nulos_por_columna.items() if nulos > 0]\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Valores nulos encontrados en: {', '.join(columnas_con_nulos)}\",\n",
    "            'detalle': nulos_por_columna\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"No se encontraron valores nulos en las columnas requeridas\"\n",
    "    }\n",
    "\n",
    "def validar_tipos_datos(df, tipos_esperados):\n",
    "    \"\"\"Valida que las columnas tengan los tipos de datos esperados.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        tipos_esperados: Diccionario con columnas y sus tipos esperados\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    # Verificamos que todas las columnas existan\n",
    "    columnas_faltantes = [col for col in tipos_esperados.keys() if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos los tipos de datos\n",
    "    tipos_incorrectos = {}\n",
    "    for columna, tipo_esperado in tipos_esperados.items():\n",
    "        tipo_actual = df[columna].dtype\n",
    "        if not pd.api.types.is_dtype_equal(tipo_actual, tipo_esperado):\n",
    "            # Para tipos numéricos, verificamos si podemos convertir sin pérdida de información\n",
    "            if pd.api.types.is_numeric_dtype(tipo_esperado) and pd.api.types.is_numeric_dtype(tipo_actual):\n",
    "                continue\n",
    "            \n",
    "            # Para fechas, verificamos si podemos convertir\n",
    "            if tipo_esperado == 'datetime64[ns]' and pd.api.types.is_string_dtype(tipo_actual):\n",
    "                try:\n",
    "                    pd.to_datetime(df[columna])\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            tipos_incorrectos[columna] = {'esperado': tipo_esperado, 'actual': str(tipo_actual)}\n",
    "    \n",
    "    if tipos_incorrectos:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Tipos de datos incorrectos en {len(tipos_incorrectos)} columnas\",\n",
    "            'detalle': tipos_incorrectos\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"Todos los tipos de datos son correctos\"\n",
    "    }\n",
    "\n",
    "def validar_rango_valores(df, rangos):\n",
    "    \"\"\"Valida que los valores estén dentro de los rangos especificados.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        rangos: Diccionario con columnas y sus rangos (min, max)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    # Verificamos que todas las columnas existan\n",
    "    columnas_faltantes = [col for col in rangos.keys() if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos los rangos\n",
    "    fuera_de_rango = {}\n",
    "    for columna, (min_val, max_val) in rangos.items():\n",
    "        # Verificamos mínimo\n",
    "        if min_val is not None:\n",
    "            valores_bajo_minimo = df[df[columna] < min_val]\n",
    "            if not valores_bajo_minimo.empty:\n",
    "                if columna not in fuera_de_rango:\n",
    "                    fuera_de_rango[columna] = {}\n",
    "                fuera_de_rango[columna]['bajo_minimo'] = {\n",
    "                    'cantidad': len(valores_bajo_minimo),\n",
    "                    'minimo_esperado': min_val,\n",
    "                    'valor_minimo_encontrado': float(valores_bajo_minimo[columna].min())\n",
    "                }\n",
    "        \n",
    "        # Verificamos máximo\n",
    "        if max_val is not None:\n",
    "            valores_sobre_maximo = df[df[columna] > max_val]\n",
    "            if not valores_sobre_maximo.empty:\n",
    "                if columna not in fuera_de_rango:\n",
    "                    fuera_de_rango[columna] = {}\n",
    "                fuera_de_rango[columna]['sobre_maximo'] = {\n",
    "                    'cantidad': len(valores_sobre_maximo),\n",
    "                    'maximo_esperado': max_val,\n",
    "                    'valor_maximo_encontrado': float(valores_sobre_maximo[columna].max())\n",
    "                }\n",
    "    \n",
    "    if fuera_de_rango:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Valores fuera de rango en {len(fuera_de_rango)} columnas\",\n",
    "            'detalle': fuera_de_rango\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"Todos los valores están dentro de los rangos especificados\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_data_validation.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import validar_completitud, validar_tipos_datos, validar_rango_valores\n",
    "\n",
    "@pytest.fixture\n",
    "def df_valido():\n",
    "    \"\"\"Fixture que crea un DataFrame válido para testing.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_con_nulos():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores nulos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', None, '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', None],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, None],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_tipos_incorrectos():\n",
    "    \"\"\"Fixture que crea un DataFrame con tipos de datos incorrectos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': ['899.99', '249.99', '59.99'],  # Strings en lugar de float\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_fuera_de_rango():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores fuera de rango.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, -3],  # Valor negativo\n",
    "        'descuento': [0.05, 0.00, 1.5],  # Descuento mayor a 1 (100%)\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_validar_completitud_sin_nulos(df_valido):\n",
    "    \"\"\"Test para validar completitud en un DataFrame sin valores nulos.\"\"\"\n",
    "    resultado = validar_completitud(df_valido)\n",
    "    assert resultado['valido'] is True\n",
    "    assert 'mensaje' in resultado\n",
    "\n",
    "def test_validar_completitud_con_nulos(df_con_nulos):\n",
    "    \"\"\"Test para validar completitud en un DataFrame con valores nulos.\"\"\"\n",
    "    resultado = validar_completitud(df_con_nulos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'error' in resultado\n",
    "    assert 'detalle' in resultado\n",
    "    assert resultado['detalle']['fecha'] == 1\n",
    "    assert resultado['detalle']['categoria'] == 1\n",
    "    assert resultado['detalle']['cantidad'] == 1\n",
    "\n",
    "def test_validar_completitud_columnas_especificas(df_con_nulos):\n",
    "    \"\"\"Test para validar completitud solo en columnas específicas.\"\"\"\n",
    "    # Validamos solo columnas que no tienen nulos\n",
    "    resultado = validar_completitud(df_con_nulos, ['id', 'producto', 'precio', 'descuento', 'total'])\n",
    "    assert resultado['valido'] is True\n",
    "    \n",
    "    # Validamos una columna que tiene nulos\n",
    "    resultado = validar_completitud(df_con_nulos, ['id', 'fecha'])\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['detalle']['fecha'] == 1\n",
    "\n",
    "def test_validar_tipos_datos_correctos(df_valido):\n",
    "    \"\"\"Test para validar tipos de datos correctos.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'precio': 'float64',\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_valido, tipos_esperados)\n",
    "    assert resultado['valido'] is True\n",
    "\n",
    "def test_validar_tipos_datos_incorrectos(df_tipos_incorrectos):\n",
    "    \"\"\"Test para validar tipos de datos incorrectos.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'precio': 'float64',  # En df_tipos_incorrectos, precio es string\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_tipos_incorrectos, tipos_esperados)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'precio' in resultado['detalle']\n",
    "\n",
    "def test_validar_rango_valores_dentro_de_rango(df_valido):\n",
    "    \"\"\"Test para validar rangos de valores dentro de los límites.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),\n",
    "        'descuento': (0, 1),\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_valido, rangos)\n",
    "    assert resultado['valido'] is True\n",
    "\n",
    "def test_validar_rango_valores_fuera_de_rango(df_fuera_de_rango):\n",
    "    \"\"\"Test para validar rangos de valores fuera de los límites.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),  # En df_fuera_de_rango, hay un valor negativo\n",
    "        'descuento': (0, 1),  # En df_fuera_de_rango, hay un descuento > 1\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_fuera_de_rango, rangos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'cantidad' in resultado['detalle']\n",
    "    assert 'descuento' in resultado['detalle']\n",
    "    assert 'bajo_minimo' in resultado['detalle']['cantidad']\n",
    "    assert 'sobre_maximo' in resultado['detalle']['descuento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos los tests de validación de datos\n",
    "!pytest -xvs test_data_validation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cobertura de Código\n",
    "\n",
    "Una métrica importante en testing es la cobertura de código, que mide qué porcentaje de nuestro código está siendo ejecutado por los tests. Pytest, junto con el plugin pytest-cov, nos permite medir y visualizar esta cobertura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos los tests con medición de cobertura\n",
    "!pytest --cov=utils test_data_processing.py test_data_validation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener un informe más detallado de la cobertura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un informe detallado de cobertura\n",
    "!pytest --cov=utils --cov-report=term-missing test_data_processing.py test_data_validation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integración con Pandas y NumPy\n",
    "\n",
    "Cuando trabajamos con pandas y NumPy en Data Engineering, hay algunas consideraciones especiales para el testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Comparación de DataFrames\n",
    "\n",
    "Para comparar DataFrames en tests, podemos usar `pd.testing.assert_frame_equal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_pandas_integration.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def filtrar_por_categoria(df, categoria):\n",
    "    \"\"\"Filtra un DataFrame por categoría.\"\"\"\n",
    "    return df[df['categoria'] == categoria].reset_index(drop=True)\n",
    "\n",
    "def test_filtrar_por_categoria():\n",
    "    # Creamos un DataFrame de prueba\n",
    "    data = {\n",
    "        'id': [1, 2, 3, 4],\n",
    "        'categoria': ['A', 'B', 'A', 'C'],\n",
    "        'valor': [10, 20, 30, 40]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Filtramos por categoría 'A'\n",
    "    resultado = filtrar_por_categoria(df, 'A')\n",
    "    \n",
    "    # Creamos el DataFrame esperado\n",
    "    esperado = pd.DataFrame({\n",
    "        'id': [1, 3],\n",
    "        'categoria': ['A', 'A'],\n",
    "        'valor': [10, 30]\n",
    "    })\n",
    "    \n",
    "    # Comparamos los DataFrames\n",
    "    pd.testing.assert_frame_equal(resultado, esperado)\n",
    "\n",
    "def test_filtrar_por_categoria_vacio():\n",
    "    # Creamos un DataFrame de prueba\n",
    "    data = {\n",
    "        'id': [1, 2, 3, 4],\n",
    "        'categoria': ['A', 'B', 'A', 'C'],\n",
    "        'valor': [10, 20, 30, 40]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Filtramos por una categoría que no existe\n",
    "    resultado = filtrar_por_categoria(df, 'D')\n",
    "    \n",
    "    # Verificamos que el resultado sea un DataFrame vacío con las mismas columnas\n",
    "    assert len(resultado) == 0\n",
    "    assert list(resultado.columns) == ['id', 'categoria', 'valor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos los tests de integración con pandas\n",
    "!pytest -xvs test_pandas_integration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Comparación de arrays NumPy\n",
    "\n",
    "Para arrays de NumPy, podemos usar `np.testing.assert_array_equal` o `np.testing.assert_allclose` para comparaciones con tolerancia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../tests/test_numpy_integration.py\n",
    "import pytest\n",
    "import numpy as np\n",
    "\n",
    "def normalizar_array(arr):\n",
    "    \"\"\"Normaliza un array para que sus valores estén entre 0 y 1.\"\"\"\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    if min_val == max_val:\n",
    "        return np.zeros_like(arr)\n",
    "    return (arr - min_val) / (max_val - min_val)\n",
    "\n",
    "def test_normalizar_array():\n",
    "    # Creamos un array de prueba\n",
    "    arr = np.array([10, 20, 30, 40, 50])\n",
    "    \n",
    "    # Normalizamos\n",
    "    resultado = normalizar_array(arr)\n",
    "    \n",
    "    # Creamos el array esperado\n",
    "    esperado = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "    \n",
    "    # Comparamos los arrays\n",
    "    np.testing.assert_allclose(resultado, esperado)\n",
    "\n",
    "def test_normalizar_array_constante():\n",
    "    # Creamos un array constante\n",
    "    arr = np.array([10, 10, 10])\n",
    "    \n",
    "    # Normalizamos\n",
    "    resultado = normalizar_array(arr)\n",
    "    \n",
    "    # Creamos el array esperado (todos ceros)\n",
    "    esperado = np.array([0.0, 0.0, 0.0])\n",
    "    \n",
    "    # Comparamos los arrays\n",
    "    np.testing.assert_array_equal(resultado, esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos los tests de integración con numpy\n",
    "!pytest -xvs test_numpy_integration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este notebook, hemos explorado en detalle las características y funcionalidades de pytest, con un enfoque específico en su aplicación para proyectos de Data Engineering. Hemos visto:\n",
    "\n",
    "1. **Fundamentos de pytest**: Sintaxis básica, ejecución de tests y aserciones.\n",
    "2. **Características avanzadas**: Fixtures, parametrización, marcadores y alcance de fixtures.\n",
    "3. **Aplicaciones específicas para Data Engineering**: Testing de funciones de transformación y validación de datos.\n",
    "4. **Cobertura de código**: Medición y visualización de la cobertura de tests.\n",
    "5. **Integración con pandas y NumPy**: Técnicas específicas para testear código que utiliza estas bibliotecas.\n",
    "\n",
    "Pytest proporciona un conjunto de herramientas potente y flexible para asegurar la calidad de nuestros proyectos de Data Engineering. Al implementar una estrategia de testing efectiva, podemos tener mayor confianza en la corrección de nuestro código y en la calidad de los datos que procesamos.\n",
    "\n",
    "En el siguiente notebook, veremos un paso a paso detallado para implementar tests en un proyecto de Data Engineering real, desde la configuración inicial hasta la ejecución y análisis de los resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
